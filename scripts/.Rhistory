upper_bound <- Q3 + 2 * IQR
# Identify outliers
outliers <- .x < lower_bound | .x > upper_bound
# Replace outliers with NA
.x[outliers] <- NA
.x
})) %>%
ungroup()
# Chunk 15
# Combine the results into a data frame
na_summary_kin <- data.frame(
NA_Count_Pre_Removal = colSums(is.na(can[, columns_to_process])),
NA_Count_Post_Removal = colSums(is.na(can_grouped[, columns_to_process])),
NA_Perc_Pre_Removal = (colSums(is.na(can[, columns_to_process])) / nrow(can)) * 100,
NA_Perc_Post_Removal = (colSums(is.na(can_grouped[, columns_to_process])) / nrow(can_grouped)) * 100
)
na_summary_kin
# Chunk 16
# Calculate means for each variable in the pre-removal dataset
means_can <- can %>%
group_by(speaker) %>%
summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>%
ungroup()
# Calculate means for each variable in the post-removal dataset
means_can_grouped <- can_grouped %>%
group_by(speaker) %>%
summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>%
ungroup()
# Combine the means into a single summary table
outlier_summary_kin <- bind_rows(
tibble(Variable = "Pre-Removal", means_can),
tibble(Variable = "Post-Removal", means_can_grouped)
)
# Chunk 17
can <- can_grouped
rm(can_grouped, means_can, means_can_grouped)
rm(columns_to_process)
# Chunk 18
# Create tibble with means and sd per speaker and vowel:
can %>%
na.omit() %>%
group_by(speaker, vowel) %>%
summarize_at(vars(dB_mean, f0_mean, f0_range, F1, F2, F3), list(mean = mean, sd = sd)) %>%
ungroup() %>%
{. ->> speakers_phon}
# Join tibble with means per speaker and vowel
can <- can %>%
left_join(speakers_phon, by = c("speaker", "vowel")) %>%
# Calculate z-scores
mutate(
db_mean_z = (dB_mean - dB_mean_mean) / dB_mean_sd,
f0_mean_z = (f0_mean - f0_mean_mean) / f0_mean_sd,
f0_range_z = (f0_range - f0_range_mean) / f0_range_sd,
F1_z = (F1 - F1_mean) / F1_sd,
F2_z = (F2 - F2_mean) / F2_sd,
F3_z = (F3 - F3_mean) / F3_sd
) %>%
# Deselect unneeded variables
select(-c(
dB_mean_sd, dB_mean_mean,
f0_mean_sd, f0_mean_mean,
f0_range_sd, f0_range_mean,
F1_sd, F1_mean,
F2_sd, F2_mean,
F3_sd, F3_mean
))
# Chunk 19
# Create tibble with means and sd per speaker and vowel for head_pos, lip_dist, and angle:
can %>%
na.omit() %>%
group_by(speaker, vowel) %>%
summarize_at(vars(head_pos, lip_dist, angle), list(mean = mean, sd = sd)) %>%
ungroup() %>%
{. ->> speakers_kin}
# Join tibble with means per speaker and vowel
can <- can %>%
left_join(speakers_kin, by = c("speaker", "vowel")) %>%
# Calculate z-scores
mutate(
head_pos_z = (head_pos - head_pos_mean) / head_pos_sd,
lip_dist_z = (lip_dist - lip_dist_mean) / lip_dist_sd,
angle_z = (angle - angle_mean) / angle_sd
) %>%
# deselect unneeded variables
select(-c(
head_pos_sd, head_pos_mean,
lip_dist_sd, lip_dist_mean,
angle_sd, angle_mean
))
# Chunk 20
can %>%
group_by(speaker) %>%
summarize_at(vars(head_pos), list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))) %>%
{. ->> speakers_pos} %>%
ungroup() %>%
print(n = Inf)
# Chunk 21
mean(speakers_pos$sd)
# Chunk 22
filter(speakers_pos, sd > 1.123773)
# Chunk 23
filter(speakers_pos, sd < 1.123773)
# Chunk 24
can <- left_join(can,
can %>%
group_by(speaker) %>%
summarize_at(vars(head_pos),
list(mean_pos = ~ mean(., na.rm = TRUE),
sd_pos = ~ sd(., na.rm = TRUE)),
na.rm = TRUE) %>%
mutate(mover = ifelse(sd_pos < 1.123773, 'no', 'yes')) %>%
ungroup())
# Chunk 25
can <- can %>%
mutate(pos_difference = head_pos - mean_pos) %>%
select(-c(sd_pos, mean_pos)) # deselect unneded variables
# Chunk 26
can_noNA <- can %>%
mutate(across(c(F1, F2, F3), ~ifelse(is.na(.), 9999, .)))
# Chunk 27
can_noNA <- mutate(can_noNA,
F1_bark = normBark(F1),
F2_bark = normBark(F2),
F3_bark = normBark(F3))
# Chunk 28
can_noNA <- mutate(can_noNA,
across(c(F1, F2, F3), ~ifelse(. == 9999, NA, .)),
across(c(F1_bark, F2_bark, F3_bark),
~ifelse(is.na(get(substring(cur_column(), 1, 2))), NA, .)))
can <- can_noNA
rm(can_noNA)
# Chunk 29
# Pivot the data to create separate columns for each variable and category
can_formants_aside <- can %>%
pivot_wider(
id_cols = c(speaker, vowel, v_pos, h_pos),
names_from = can_size,
values_from = c(F1, F2, F3, lip_dist, F1_z, F2_z, F3_z, F1_bark, F2_bark, F3_bark),
names_sep = "_"
) %>%
# Rename columns for clarity
rename(
F1_large = F1_large,
F1_small = F1_small,
F2_large = F2_large,
F2_small = F2_small,
F3_large = F3_large,
F3_small = F3_small,
lip_dist_large = lip_dist_large,
lip_dist_small = lip_dist_small,
F1_z_large = F1_z_large,
F1_z_small = F1_z_small,
F2_z_large = F2_z_large,
F2_z_small = F2_z_small,
F3_z_large = F3_z_large,
F3_z_small = F3_z_small,
F1_bark_large = F1_bark_large,
F1_bark_small = F1_bark_small,
F2_bark_large = F2_bark_large,
F2_bark_small = F2_bark_small,
F3_bark_large = F3_bark_large,
F3_bark_small = F3_bark_small
)
# View the resulting dataframe
print(can_formants_aside)
# Chunk 30
can_formants_aside <- mutate(can_formants_aside,
dist_size_hz = sqrt((F1_large - F1_small)^2 + (F2_large - F2_small)^2),
dist_size_z = sqrt((F1_z_large - F1_z_small)^2 + (F2_z_large - F2_z_small)^2),
dist_size_bark = sqrt((F1_bark_large - F1_bark_small)^2 + (F2_bark_large - F2_bark_small)^2)
)
# Chunk 31
can <- can %>%
mutate(
vowel_s = if_else(vowel == "I", -0.5, 0.5),
can_size_s = if_else(can_size == "small", -0.5, 0.5),
mover_s = if_else(mover == "no", -0.5, 0.5)
)
# Chunk 32
length(unique(can$speaker))
# Chunk 33
can %>%
group_by(speaker) %>%
summarize(num_unique_realizations = n_distinct(paste(can_size, v_pos, h_pos, vowel))) %>%
ungroup() %>%
print(n = 30)
# Chunk 34
can %>%
group_by(speaker) %>%
summarize(
across(c(dB_mean, f0_mean, f0_range, F1, F2, F3, head_pos, lip_dist, angle),
~sum(is.na(.))),
.groups = 'drop'
) %>%
print(n = 30)
# Chunk 35
print(speakers_phon, n = 60)
# Chunk 36
print(speakers_kin, n = 60)
# Chunk 37
write.csv(can, paste0(data, "can.csv"), row.names = FALSE)
formants_a_large <- can %>%
filter(vowel == "a") %>%
filter(.,can_size == 'large')
formants_a_small <- can %>%
filter(vowel == "a") %>%
filter(.,can_size == 'small')
formants_i_large <- can %>%
filter(vowel == "I") %>%
filter(.,can_size == 'large')
formants_i_small <- can %>%
filter(vowel == "I") %>%
filter(.,can_size == 'small')
area_a_large = ggplot(formants_a_large,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
pb = ggplot_build(area_a_large)
el = pb$data[[2]][c("x", "y")]
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
area_a_large <- pi*min(dist2center)*max(dist2center)
area_a_large
# Plot object
area_a_large = ggplot(formants_a_large,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_a_large)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_a_large <- pi*min(dist2center)*max(dist2center)
area_a_large
# Plot object
area_a_small = ggplot(formants_a_small,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_a_small)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_a_small <- pi*min(dist2center)*max(dist2center)
area_a_small
# Plot object
area_i_large = ggplot(formants_i_large,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_i_large)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_i_large <- pi*min(dist2center)*max(dist2center)
area_i_large
# Plot object
area_i_small = ggplot(formants_i_small,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_i_small)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_i_small <- pi*min(dist2center)*max(dist2center)
area_i_small
areas <- tribble(
~size_large, ~size_small,
area_a_large, area_a_small,
area_i_large, area_i_small)
t.test(areas$size_large, areas$size_small, paired = T)
rm(area_a_large,area_a_small,area_i_large,area_i_small,ctr,dist2center,pb,el)
can <- can %>%
mutate(f_disp = ((F2 - F1) + (F3 - F2)) / 2)
can %>%
group_by(speaker, vowel) %>%
summarize(mean_f_disp = mean(f_disp, na.rm = TRUE)) %>%
ungroup() %>%
print(n = Inf)
cor.test(can$lip_dist, can$F1)
ggplot(can,
aes(x = lip_dist,
y = F1)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
cor.test(can$lip_dist, can$f_disp)
ggplot(can,
aes(x = lip_dist,
y = f_disp)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
# Histogram for lip_dist
ggplot(can, aes(x = lip_dist)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
labs(title = "Distribution of lip_dist", x = "lip_dist", y = "Frequency") +
theme_minimal()
# looks kind of normal
# Histogram for f_disp
ggplot(can, aes(x = f_disp)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
labs(title = "Distribution of f_disp", x = "f_disp", y = "Frequency") +
theme_minimal()
# this is skewed, I would opt for lognormal
# Descriptive Statistics
summary(can$lip_dist)
summary(can$f_disp)
# In intercept is 1000
log(4)
# If we set the prior to normal(0,1), what would be the boundaries
exp(log(4)-.5); exp(log(4)+.5)
# If we set the prior to normal(0,2), what would be the boundaries
exp(log(4)-1); exp(log(4)+1)
# If we set the prior to normal(0,3), what would be the boundaries
exp(log(4)-1.5); exp(log(4)+1.5)
get_prior(formula = lip_dist ~ 1 + vowel_s + can_size_s + head_pos + h_pos + v_pos + height + # head_pos and v_pos will be separated
(1 + vowel_s + can_size_s + head_pos + h_pos + v_pos || speaker),
data = can,
family = lognormal())
priors_maxH2_lip <- c(
prior('normal(0, 3)', class = 'Intercept'),
prior('normal(0, 1)', class = b)
)
mdl_maxH2_lip_headPos <- brm(lip_dist ~
1 + vowel_s + can_size_s +
head_pos + h_pos + height +
(1 + vowel_s + can_size_s +
head_pos + h_pos || speaker),
data = can,
prior = priors_maxH2_lip,
family = lognormal(),
#backend = "cmdstanr",
cores = 4,
chains = 4,
iter = 8000,
warmup = 4000,
seed = 998,
save_pars = save_pars(all = TRUE),
control = list(max_treedepth = 13,
adapt_delta = 0.99),
file = paste0(models, "mdl_maxH2_lip_headPos.rds"))
# if we need to compress the model more
#saveRDS(mdl_maxH2_lip_headPos, file = paste0(models, "mdl_maxH2_lip_headPos.rds"), compress = "xz")
mdl_maxH2_lip_headPos <- readRDS(paste0(models, "mdl_maxH2_lip_headPos.rds"))
beepr::beep()
summary(mdl_maxH2_lip_headPos)
mdl_maxH2_lip_vPos <- brm(lip_dist ~ 1 + vowel_s + can_size_s +
h_pos + v_pos + height +
(1 + vowel_s + can_size_s +
h_pos + v_pos || speaker),
data = can,
prior = priors_maxH2_lip,
family = lognormal(),
#backend = "cmdstanr",
cores = 4,
chains = 4,
iter = 8000,
warmup = 4000,
seed = 998,
save_pars = save_pars(all = TRUE),
control = list(max_treedepth = 13,
adapt_delta = 0.99),
file = paste0(models, "mdl_maxH2_lip_vPos.rds"))
# if we need to compress the model more
#saveRDS(mdl_maxH2_lip_vPos, file = paste0(models, "mdl_maxH2_lip_vPos.rds"), compress = "xz")
mdl_maxH2_lip_vPos <- readRDS(paste0(models, "mdl_maxH2_lip_vPos.rds"))
# beepr::beep()
lip_vowel_size <- ggplot(can,
aes(y = lip_dist,
x = vowel,
fill = can_size)) +
geom_violin(position = position_dodge(1),
trim = FALSE,
alpha = 0.4) +
# adds median and quartile:
geom_boxplot(width = 0.1,
position = position_dodge((1)),
alpha = 0.6,
outlier.shape = NA, # Hides outliers.
notch = T, #  Notches are used to compare groups; if the notches of two boxes do not overlap, this suggests that the medians are significantly different.
coef = 0) + # Length of the whiskers as multiple of IQR. Defaults to 1.5.
scale_fill_manual(values = colorBlindBlack8) +
labs(x = "Vowel",
y = "Lip opening",
fill = "Can size") +
theme_bw()+
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14, face = "bold"),
legend.title = element_text(size = 14),
legend.text = element_text(size = 12))
lip_vowel_size
# ggsave(plot = lip,
#        filename = paste0(plots, "lip_vowel_size.pdf"),
#        width = 8, height = 5)
# Extracting posterior samples
post_maxH2_lip_headPos <- mdl_maxH2_lip_headPos %>%
gather_draws(b_vowel_s, b_can_size_s, b_head_pos, b_h_pos, b_height)
# Plotting intervals with densities
postplot_maxH2_lip_headPos <-
ggplot(post_maxH2_lip_headPos,
aes(x = .value, y = .variable)) +
stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
linetype = "dashed", color = "grey", size = 1) +
theme_bw() +
labs(x = "Posterior density", y = "Variable") +
scale_y_discrete(labels = c("Can size", "Horizontal pos.", "Head position", "Height", "Vowel")) #+ # Must be in alphabetical order
#scale_x_continuous(limits = c(-0.13, 0.01))
postplot_maxH2_lip_headPos
print(postplot_maxH2_lip_headPos +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14,
face = "bold")))
ggsave(filename = paste0(plots, "postplot_maxH2_lip_headPos.pdf"),
plot = last_plot(),
width = 10, height = 8)
# Extracting posterior samples
post_maxH2_lip_headPos <- mdl_maxH2_lip_headPos %>%
gather_draws(b_vowel_s, b_can_size_s, b_head_pos, b_h_pos, b_height)
# Plotting intervals with densities
postplot_maxH2_lip_headPos <-
ggplot(post_maxH2_lip_headPos,
aes(x = .value, y = .variable)) +
stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
linetype = "dashed", color = "grey", size = 1) +
theme_bw() +
labs(x = "Posterior density", y = "Variable") +
scale_y_discrete(labels = c("Can size", "Horizontal pos.", "Height", "Vertical pos.", "Vowel")) #+ # Must be in alphabetical order
#scale_x_continuous(limits = c(-0.13, 0.01))
print(postplot_maxH2_lip_headPos +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14,
face = "bold")))
# ggsave(filename = paste0(plots, "postplot_maxH2_lip_headPos.pdf"),
#        plot = last_plot(),
#        width = 10, height = 8)
print(postplot_maxH2_lip_headPos +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14,
face = "bold")))
# Extracting posterior samples
post_maxH2_lip_headPos <- mdl_maxH2_lip_headPos %>%
gather_draws(b_vowel_s, b_can_size_s, b_head_pos, b_h_pos, b_height)
# Plotting intervals with densities
postplot_maxH2_lip_headPos <-
ggplot(post_maxH2_lip_headPos,
aes(x = .value, y = .variable)) +
stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
linetype = "dashed", color = "grey", size = 1) +
theme_bw() +
labs(x = "Posterior density", y = "Variable") +
scale_y_discrete(labels = c("Can size", "Horizontal pos.", "Head position", "Height", "Vowel")) #+ # Must be in alphabetical order
#scale_x_continuous(limits = c(-0.13, 0.01))
print(postplot_maxH2_lip_headPos +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14,
face = "bold")))
# ggsave(filename = paste0(plots, "postplot_maxH2_lip_headPos.pdf"),
#        plot = last_plot(),
#        width = 10, height = 8)
# Extracting posterior samples
post_maxH2_lip_vPos <- mdl_maxH2_lip_vPos %>%
gather_draws(b_vowel_s, b_can_size_s, b_v_pos, b_h_pos, b_height)
# Plotting intervals with densities
postplot_maxH2_lip_vPos <-
ggplot(post_maxH2_lip_vPos,
aes(x = .value, y = .variable)) +
stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
linetype = "dashed", color = "grey", size = 1) +
theme_bw() +
labs(x = "Posterior density", y = "Variable") +
scale_y_discrete(labels = c("Can size", "Horizontal pos.", "Height", "Vertical pos.", "Vowel")) #+ # Must be in alphabetical order
#scale_x_continuous(limits = c(-0.13, 0.01))
print(postplot_maxH2_lip_vPos +
theme(axis.text = element_text(size = 12),
axis.title = element_text(size = 14,
face = "bold")))
ggsave(filename = paste0(plots, "postplot_maxH2_lip_vPos.pdf"),
plot = last_plot(),
width = 10, height = 8)
