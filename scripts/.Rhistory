summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>%
ungroup()
# Combine the means into a single summary table
outlier_summary_acc <- bind_rows(
tibble(Variable = "Pre-Removal", means_can),
tibble(Variable = "Post-Removal", means_can_grouped)
)
# Chunk 14
can <- can_grouped
rm(can_grouped, means_can, means_can_grouped)
rm(columns_to_process)
# Chunk 15
# Columns to process
columns_to_process <- c("head_pos", "angle", "lip_dist")
# Group by Language and Participant and then loop through each column
can_grouped <- can %>%
group_by(speaker) %>%
mutate(across(all_of(columns_to_process), .fns = ~{
cat("Processing column:", deparse(substitute(.)), "\n")
# Calculate IQR
Q1 <- quantile(.x, 0.25, na.rm = TRUE)
Q3 <- quantile(.x, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Define lower and upper bounds for outliers
lower_bound <- Q1 - 2 * IQR
upper_bound <- Q3 + 2 * IQR
# Identify outliers
outliers <- .x < lower_bound | .x > upper_bound
# Replace outliers with NA
.x[outliers] <- NA
.x
})) %>%
ungroup()
# Chunk 16
# Combine the results into a data frame
na_summary_kin <- data.frame(
NA_Count_Pre_Removal = colSums(is.na(can[, columns_to_process])),
NA_Count_Post_Removal = colSums(is.na(can_grouped[, columns_to_process])),
NA_Perc_Pre_Removal = (colSums(is.na(can[, columns_to_process])) / nrow(can)) * 100,
NA_Perc_Post_Removal = (colSums(is.na(can_grouped[, columns_to_process])) / nrow(can_grouped)) * 100
)
na_summary_kin
# Chunk 17
# Calculate means for each variable in the pre-removal dataset
means_can <- can %>%
group_by(speaker) %>%
summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>%
ungroup()
# Calculate means for each variable in the post-removal dataset
means_can_grouped <- can_grouped %>%
group_by(speaker) %>%
summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>%
ungroup()
# Combine the means into a single summary table
outlier_summary_kin <- bind_rows(
tibble(Variable = "Pre-Removal", means_can),
tibble(Variable = "Post-Removal", means_can_grouped)
)
# Chunk 18
can <- can_grouped
rm(can_grouped, means_can, means_can_grouped)
rm(columns_to_process)
# Chunk 19
# Create tibble with means and sd per speaker and vowel:
can %>%
na.omit() %>%
group_by(speaker, vowel) %>%
summarize_at(vars(dB_mean, f0_mean, f0_range, F1, F2, F3), list(mean = mean, sd = sd)) %>%
ungroup() %>%
{. ->> speakers_phon}
# Join tibble with means per speaker and vowel
can <- can %>%
left_join(speakers_phon, by = c("speaker", "vowel")) %>%
# Calculate z-scores
mutate(
db_mean_z = (dB_mean - dB_mean_mean) / dB_mean_sd,
f0_mean_z = (f0_mean - f0_mean_mean) / f0_mean_sd,
f0_range_z = (f0_range - f0_range_mean) / f0_range_sd,
F1_z = (F1 - F1_mean) / F1_sd,
F2_z = (F2 - F2_mean) / F2_sd,
F3_z = (F3 - F3_mean) / F3_sd
) %>%
# Deselect unneeded variables
select(-c(
dB_mean_sd, dB_mean_mean,
f0_mean_sd, f0_mean_mean,
f0_range_sd, f0_range_mean,
F1_sd, F1_mean,
F2_sd, F2_mean,
F3_sd, F3_mean
))
# Chunk 20
# Create tibble with means and sd per speaker and vowel for head_pos, lip_dist, and angle:
can %>%
na.omit() %>%
group_by(speaker, vowel) %>%
summarize_at(vars(head_pos, lip_dist, angle), list(mean = mean, sd = sd)) %>%
ungroup() %>%
{. ->> speakers_kin}
# Join tibble with means per speaker and vowel
can <- can %>%
left_join(speakers_kin, by = c("speaker", "vowel")) %>%
# Calculate z-scores
mutate(
head_pos_z = (head_pos - head_pos_mean) / head_pos_sd,
lip_dist_z = (lip_dist - lip_dist_mean) / lip_dist_sd,
angle_z = (angle - angle_mean) / angle_sd
) %>%
# deselect unneeded variables
select(-c(
head_pos_sd, head_pos_mean,
lip_dist_sd, lip_dist_mean,
angle_sd, angle_mean
))
# Chunk 21
can %>%
group_by(speaker) %>%
summarize_at(vars(head_pos), list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))) %>%
{. ->> speakers_pos} %>%
ungroup() %>%
print(n = Inf)
# Chunk 22
mean(speakers_pos$sd)
# Chunk 23
filter(speakers_pos, sd > 1.123773)
# Chunk 24
filter(speakers_pos, sd < 1.123773)
# Chunk 25
can <- left_join(can,
can %>%
group_by(speaker) %>%
summarize_at(vars(head_pos),
list(mean_pos = ~ mean(., na.rm = TRUE),
sd_pos = ~ sd(., na.rm = TRUE)),
na.rm = TRUE) %>%
mutate(mover = ifelse(sd_pos < 1.123773, 'no', 'yes')) %>%
ungroup())
# Chunk 26
can <- can %>%
mutate(pos_difference = head_pos - mean_pos) %>%
select(-c(sd_pos, mean_pos)) # deselect unneded variables
# Chunk 27
can_noNA <- can %>%
mutate(across(c(F1, F2, F3), ~ifelse(is.na(.), 9999, .)))
# Chunk 28
can_noNA <- mutate(can_noNA,
F1_bark = normBark(F1),
F2_bark = normBark(F2),
F3_bark = normBark(F3))
# Chunk 29
can_noNA <- mutate(can_noNA,
across(c(F1, F2, F3), ~ifelse(. == 9999, NA, .)),
across(c(F1_bark, F2_bark, F3_bark),
~ifelse(is.na(get(substring(cur_column(), 1, 2))), NA, .)))
can <- can_noNA
rm(can_noNA)
# Chunk 30
# Pivot the data to create separate columns for each variable and category
can_formants_aside <- can %>%
pivot_wider(
id_cols = c(speaker, vowel, v_pos, h_pos),
names_from = can_size,
values_from = c(F1, F2, F3, lip_dist, F1_z, F2_z, F3_z, F1_bark, F2_bark, F3_bark),
names_sep = "_"
) %>%
# Rename columns for clarity
rename(
F1_large = F1_large,
F1_small = F1_small,
F2_large = F2_large,
F2_small = F2_small,
F3_large = F3_large,
F3_small = F3_small,
lip_dist_large = lip_dist_large,
lip_dist_small = lip_dist_small,
F1_z_large = F1_z_large,
F1_z_small = F1_z_small,
F2_z_large = F2_z_large,
F2_z_small = F2_z_small,
F3_z_large = F3_z_large,
F3_z_small = F3_z_small,
F1_bark_large = F1_bark_large,
F1_bark_small = F1_bark_small,
F2_bark_large = F2_bark_large,
F2_bark_small = F2_bark_small,
F3_bark_large = F3_bark_large,
F3_bark_small = F3_bark_small
)
# View the resulting dataframe
print(can_formants_aside)
# Chunk 31
can_formants_aside <- mutate(can_formants_aside,
dist_size_hz = sqrt((F1_large - F1_small)^2 + (F2_large - F2_small)^2),
dist_size_z = sqrt((F1_z_large - F1_z_small)^2 + (F2_z_large - F2_z_small)^2),
dist_size_bark = sqrt((F1_bark_large - F1_bark_small)^2 + (F2_bark_large - F2_bark_small)^2)
)
# Chunk 32
can <- can %>%
mutate(
vowel_s = if_else(vowel == "I", -0.5, 0.5),
can_size_s = if_else(can_size == "small", -0.5, 0.5),
mover_s = if_else(mover == "no", -0.5, 0.5)
)
# Chunk 33
length(unique(can$speaker))
# Chunk 34
can %>%
group_by(speaker) %>%
summarize(num_unique_realizations = n_distinct(paste(can_size, v_pos, h_pos, vowel))) %>%
ungroup() %>%
print(n = 30)
# Chunk 35
can %>%
group_by(speaker) %>%
summarize(
across(c(dB_mean, f0_mean, f0_range, F1, F2, F3, head_pos, lip_dist, angle),
~sum(is.na(.))),
.groups = 'drop'
) %>%
print(n = 30)
# Chunk 36
print(speakers_phon, n = 60)
# Chunk 37
print(speakers_kin, n = 60)
# Chunk 38
summary(can$age)
# Chunk 39
summary(can$height)
# Chunk 40
summary(as.factor(can$monolingual))
# meaning 5 bilingual, 25 monolingual
# Chunk 41
summary(as.factor(can$hand))
# meaning 1 left, 29 right
# Chunk 42
write.csv(can, paste0(data, "can.csv"), row.names = FALSE)
# Chunk 43
cor.test(can$angle, can$head_pos)
# what will happen if we use z-normalized values
cor.test(can$angle_z, can$head_pos_z)
# the correlation skyrocketed! but it was there anyway
# Chunk 44
ggplot(can,
aes(x = head_pos,
y = angle)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
# Chunk 45
ggplot(can,
aes(x = head_pos_z,
y = angle_z)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
# Chunk 46
# Plot for head_pos vs f0_mean_z
f0_head_pos <- ggplot(can,
aes(x = f0_mean_z,
y = head_pos_z)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = FALSE) +
labs(title = "Head position vs f0 mean")
# Plot for angle vs f0_mean_z
f0_angle <- ggplot(can,
aes(x = f0_mean_z,
y = angle_z)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = FALSE) +
labs(title = "Angle vs f0 mean")
# Arrange plots side by side
grid.arrange(f0_head_pos, f0_angle, ncol = 2)
# Chunk 47
cor.test(can$head_pos, can$v_pos)
# what will happen if we use z-normalized values
cor.test(can$head_pos_z, can$v_pos)
cor.test(can$head_pos, can$v_pos)
# what will happen if we use z-normalized values
cor.test(can$head_pos_z, can$v_pos)
ggplot(can,
aes(x = v_pos,
y = head_pos)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
ggplot(can,
aes(x = v_pos,
y = head_pos_z)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
cor.test(can$lip_dist, can$f_disp)
formants_a_large <- can %>%
filter(vowel == "a") %>%
filter(.,can_size == 'large')
formants_a_small <- can %>%
filter(vowel == "a") %>%
filter(.,can_size == 'small')
formants_i_large <- can %>%
filter(vowel == "I") %>%
filter(.,can_size == 'large')
formants_i_small <- can %>%
filter(vowel == "I") %>%
filter(.,can_size == 'small')
# Plot object
area_a_large = ggplot(formants_a_large,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_a_large)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_a_large <- pi*min(dist2center)*max(dist2center)
area_a_large
# Plot object
area_a_small = ggplot(formants_a_small,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_a_small)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_a_small <- pi*min(dist2center)*max(dist2center)
area_a_small
# Plot object
area_i_large = ggplot(formants_i_large,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_i_large)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_i_large <- pi*min(dist2center)*max(dist2center)
area_i_large
# Plot object
area_i_small = ggplot(formants_i_small,
aes(y = F1,
x = F2)) +
geom_point() +
stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
# Get ellipse coordinates from plot
pb = ggplot_build(area_i_small)
el = pb$data[[2]][c("x", "y")]
# Center of ellipse
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
# Calculate distance to center from each point on the ellipse
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
# Calculate area of ellipse from semi-major and semi-minor axes.
# These are, respectively, the largest and smallest values of dist2center.
area_i_small <- pi*min(dist2center)*max(dist2center)
area_i_small
areas <- tribble(
~size_large, ~size_small,
area_a_large, area_a_small,
area_i_large, area_i_small)
t.test(areas$size_large, areas$size_small, paired = T)
rm(area_a_large,area_a_small,area_i_large,area_i_small,ctr,dist2center,pb,el)
can <- can %>%
mutate(f_disp = ((F2 - F1) + (F3 - F2)) / 2)
can %>%
group_by(speaker, vowel) %>%
summarize(mean_f_disp = mean(f_disp, na.rm = TRUE)) %>%
ungroup() %>%
print(n = Inf)
cor.test(can$lip_dist, can$F1)
cor.test(can$lip_dist, can$f_disp)
ggplot(can,
aes(x = lip_dist,
y = f_disp)) +
geom_point(alpha = 0.2) +
geom_smooth(size = 1,
method = lm,
se = F)
hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
exp(fixef(mdl_maxH1_headPos)[1,1]) # intercept in Hz
(exp(fixef(mdl_maxH1_headPos)[1,1])*exp(fixef(mdl_maxH1_headPos)[2,1]))-exp(fixef(mdl_maxH1_headPos)[1,1]) # estimate vowel_s in Hz (negative)
(exp(fixef(mdl_maxH1_headPos)[1,1])*exp(fixef(mdl_maxH1_headPos)[4,1]))-exp(fixef(mdl_maxH1_headPos)[1,1]) # estimate head_pos in Hz (positive)
exp(fixef(mdl_maxH1_headPos))
(exp(fixef(mdl_maxH1_headPos)[1,1])*exp(fixef(mdl_maxH1_headPos)[6,1]))-exp(fixef(mdl_maxH1_headPos)[1,1]) # estimate head_pos in Hz (positive)
hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
(exp(fixef(mdl_maxH1_headPos)[1,1])*exp(fixef(mdl_maxH1_headPos)[6,1]))-exp(fixef(mdl_maxH1_headPos)[1,1]) # estimate height in Hz (positive)
hypothesis(mdl_maxH1_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
(exp(fixef(mdl_maxH1_vPos)[1,1])*exp(fixef(mdl_maxH1_vPos)[2,1]))-exp(fixef(mdl_maxH1_vPos)[1,1]) # estimate vowel_s in Hz (negative)
(exp(fixef(mdl_maxH1_vPos)[1,1])*exp(fixef(mdl_maxH1_vPos)[4,1]))-exp(fixef(mdl_maxH1_vPos)[1,1]) # estimate v_pos in Hz (positive)
(exp(fixef(mdl_maxH1_vPos)[1,1])*exp(fixef(mdl_maxH1_vPos)[2,1]))-exp(fixef(mdl_maxH1_vPos)[1,1]) # estimate vowel_s in Hz (negative)
(exp(fixef(mdl_maxH1_vPos)[1,1])*exp(fixef(mdl_maxH1_vPos)[4,1]))-exp(fixef(mdl_maxH1_vPos)[1,1]) # estimate v_pos in Hz (positive)
pp_check(mdl_maxH1_vPos, ndraws = 100)
hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
hypothesis(mdl_maxH1_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
cor(can$v_pos,can$height)
corr.test(can$v_pos,can$height)
cor.test(can$v_pos,can$height)
can %>%
group_by(speaker) %>%
summarize_at(vars(head_pos), list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))) %>%
{. ->> speakers_pos} %>%
ungroup() %>%
print(n = Inf)
View(speakers_kin)
can %>%
group_by(speaker) %>%
summarize(head_range = max(head_pos, na.rm = TRUE) - min(head_pos, na.rm = TRUE)) %>%
ungroup() %>%
{. ->> head_range} %>%
print(n = 30)
can %>%
group_by(speaker) %>%
summarize(head_range = max(head_pos, na.rm = TRUE) - min(head_pos, na.rm = TRUE)) %>%
ungroup() %>%
arrange(desc(head_range)) %>%
{. ->> head_range} %>%
print(n = 30)
brmstools::forest(mdl_maxH1_headPos,
grouping = "speaker",
pars = "head_pos",
digits = 0,
sort = T)
# See new way:
# https://github.com/mvuorre/brmstools?tab=readme-ov-file#forest-plots
can %>%
group_by(speaker) %>%
summarize_at(vars(head_pos), list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))) %>%
{. ->> speakers_pos} %>%
ungroup() %>%
print(n = Inf)
mean(speakers_pos$sd)
hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
summary(can$head_pos) # the unit is centimeters
exp(fixef(mdl_maxH1_headPos))
summary(mdl_maxH1_headPos)
hypothesis(mdl_maxH2_lip_headPos, c("vowel_s > 0", "head_pos > 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[2,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate vowel_s in cm, i.e., difference between a and i is 50 mm
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[4,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate head_pos in cm (positive), i.e., every 1 cm change in head_pos causes a change in lip_dist of
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[6,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate height in cm, i.e., difference between a and i is 50 mm
hypothesis(mdl_maxH2_lip_vPos, c("vowel_s > 0", "v_pos < 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
(exp(fixef(mdl_maxH2_lip_vPos)[1,1])*exp(fixef(mdl_maxH2_lip_vPos)[4,1]))-exp(fixef(mdl_maxH2_lip_vPos)[1,1]) # estimate v_pos in cm (positive), i.e., every step change in v_pos causes a change in lip_dist of 3 mm
0.003500904*10
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[4,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate head_pos in cm (positive), i.e., every 1 cm change in head_pos causes a change in lip_dist of
(exp(fixef(mdl_maxH2_lip_vPos)[1,1])*exp(fixef(mdl_maxH2_lip_vPos)[4,1]))-exp(fixef(mdl_maxH2_lip_vPos)[1,1]) # estimate v_pos in cm (positive), i.e., every step change in v_pos causes a change in lip_dist of 0.03 mm
(exp(fixef(mdl_maxH2_lip_vPos)[1,1])*exp(fixef(mdl_maxH2_lip_vPos)[2,1]))-exp(fixef(mdl_maxH2_lip_vPos)[1,1]) # estimate vowel_s in cm, i.e., difference between a and i is 50 mm
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[4,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate head_pos in cm (positive), i.e., every 1 cm change in head_pos causes a change in lip_dist of
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[2,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate vowel_s in cm, i.e., difference between a and i is 5 mm
exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # intercept in cm
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[4,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate head_pos in cm (positive), i.e., every 1 cm change in head_pos causes a change in lip_dist of
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[6,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate height in cm, i.e., every 1 cm change in height causes a change in lip_dist of
hypothesis(mdl_maxH2_form_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
(exp(fixef(mdl_maxH2_form_headPos)[1,1])*exp(fixef(mdl_maxH2_form_headPos)[4,1]))-exp(fixef(mdl_maxH2_form_headPos)[1,1]) # estimate head_pos in Hz (positive), i.e., every 1 cm change in head_pos causes a change in formant dispersion of... (not reliable though)
(exp(fixef(mdl_maxH2_form_headPos)[1,1])*exp(fixef(mdl_maxH2_form_headPos)[2,1]))-exp(fixef(mdl_maxH2_form_headPos)[1,1])  # estimate vowel_s in Hz (negative), i.e., the formant dispersion difference between a and i
hypothesis(mdl_maxH2_form_vPos, c("vowel_s < 0", "v_pos > 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
(exp(fixef(mdl_maxH2_form_vPos)[1,1])*exp(fixef(mdl_maxH2_form_vPos)[2,1]))-exp(fixef(mdl_maxH2_form_vPos)[1,1])  # estimate vowel_s in Hz (negative), i.e., the formant dispersion difference between a and i
knitr::opts_chunk$set(echo = TRUE)
`%>%` <- magrittr::`%>%`
#library(tidyverse)
# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path
#setwd(dirname(parentfolder))
parentfolder <- getwd()
data <- paste0(parentfolder, '/data/')
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
`%>%` <- magrittr::`%>%`
# Chunk 2: pckgs
#library(tidyverse)
# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path
#setwd(dirname(parentfolder))
parentfolder <- getwd()
data <- paste0(parentfolder, '/data/')
# Chunk 3: load data
web <- read.csv(paste0(data, "r_l_web.csv"), sep = ",")
knitr::opts_chunk$set(echo = TRUE)
`%>%` <- magrittr::`%>%`
#library(tidyverse)
# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path
#setwd(dirname(parentfolder))
parentfolder <- getwd()
data <- paste0(parentfolder, '/data/')
web <- read.csv(paste0(data, "r_l_web.csv"), sep = ",")
