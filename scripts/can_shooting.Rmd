---
title: "Exploring Iconic Prosody and Sensorimotor Properties"
author: "Aleksandra Ćwiek & Susanne Fuchs"
date: "2023-12-04"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
    toc_float: yes
    df_print: paged
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Set up and load in data

```{r folders and packages, echo=TRUE, message=FALSE, warning=FALSE}
# Set the script's path as working directory
parentfolder = rstudioapi::getActiveDocumentContext()$path 
setwd(dirname(parentfolder))
parentfolder <- dirname(getwd())

data          <- paste0(parentfolder, '/data/')
models        <- paste0(parentfolder, '/models/')
plots         <- paste0(parentfolder, '/plots/')
scripts       <- paste0(parentfolder, '/scripts/')

# Load in packages
library(tidyverse) # data wrangling
library(gridExtra) # plots side by side
library(iemisc) # for acosd, which gives inverse cosine in degrees (standard in R is radians)
library(broom) # for tidy model outputs
library(brms)
# option for Bayesian regression models:
# use all available cores for parallel computing
options(mc.cores = parallel::detectCores())
library(HDInterval) # package for credible interval computation
library(tidybayes) # plotting
# library(brmstools) # forest plot but the package is no longer maintained
library(phonR) # for formant plots

# Use a colorblind-friendly palette
colorBlindBlack8  <- c("#000000", "#E69F00", "#56B4E9", "#009E73", 
                       "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Load data:

```{r load data, message=FALSE, warning=FALSE}
can = read_delim(paste0(data,'vowels-only.txt'), delim = '\t', col_names = TRUE, na = "NA")
```

Remove columns that are repetitive:

```{r remove columns, message=FALSE, warning=FALSE}
can <- can %>%
  select(-file, -sound.name, -Fs, -gender)
```

# Background on the data and analysis

## Method

Participants stand in front of a wall (approx. 1m distance) and are asked to shoot a can appearing on the wall. They should shoot it with a laser pointer by pointing the laser at the can, while uttering the word appearing on the can (piff\|paff) at the same time. The can appears on different positions -- on the 5x5 grid -- and in two different sizes.

Combinations: 25 positions x 2 sizes x 2 words/vowels; N = 100 items per participant.

Overall duration ca. 10 minutes.

Marker coding:

-   rg - right glasses
-   mg - mid glasses
-   lg - left glasses
-   ul - upper lip
-   jaw - lower lip/jaw
-   rw - right wrist
-   re - right elbow
-   rs - right shoulder
-   lw - left wrist
-   le - left elbow
-   ls - left shoulder
-   pointer - laser pointer
-   f - front chest
-   c7 - c7
-   b - back chest

## Hypotheses

Both hypotheses are grounded in the human body and seek to explain iconic prosody with physiological relationships.

1.  Fundamental frequency is influenced by head position, specifically, that the more upward the head is rotated, the higher the fundamental frequency.

    This hypothesis aims to investigate the missing link between the vertical position of an object and *f*0, and whether an upward-looking head position can drive the cross-modal iconic effect. We expect to find a change in *f*0 due to head movement since moving the head upwards engages the muscles around the larynx, which are responsible for *f*0 change.

2.  The degree of jaw opening is influenced by the size of an object being named, with a larger object resulting in a larger degree of jaw opening.

    Jaw opening is a physical factor that affects F1, and as such, it is used as the primary measurement in this study to assess the anatomical basis for iconicity. The relationship between F1 and object size has been demonstrated in speech perception, with a higher F1 perceived as coming from a larger source. However, this relationship has yet to be tested from the perspective of speech production.

## Explain variables

The columns in the raw data file represent the following variables:

-   *subject*: participant number (total before exclusions = 31)
-   *condition*: this is a code that contains can size, vowel, vertical and horizontal pose together
-   *part*: the experiment was divided in two parts and this column contains this information
-   *size*: the size of the can stimulus (large vs. small)
-   *v.pos*: vertical position from 1 (top) to 5 (bottom)
-   *h.pos*: horizontal position from 1 (leftmost) to 5 (rightmost)
-   *text*: vowel segment ([ɪ] vs. [a])
-   *start*, *end*, *duration*: beginning, end, duration of the vowel segment
-   *overall_dB*: mean intensity in dB
-   *min_f0*, *max_f0*, *mean_f0*: min, max, mean *f*0 within the vowel segment
-   *X50_F1*, *X50_F2*, *X50_F3*: first, second, third formant of the vowel interval, measured at the midpoint of the interval
-   *dataset*: which pre-randomized presentation was used (1--5)
-   *age*: age of the participant
-   *height*: self-reported height of the participant
-   *hand*: self-reported handedness
-   *monolingual*: binary variable of the participant was monolingual
-   *x_mg_mean*, *y_mg_mean*, *z_mg_mean*: three-dimensional coordinates of the point in the middle of the glasses (between the eyes; used to control for head tilt)
-   *x_f_mean*, *y_f_mean*, *z_f_mean*: three-dimensional coordinates of the point on the front of participant's body (on the sternum; used as a reference point)
-   *x_rw_mean*, *y_rw_mean*, *z_rw_mean*: three-dimensional coordinates of the right wrist (used to control for hand movement)
-   *x_c7_mean*, *y_c7_mean*, *z_c7_mean*: three-dimensional coordinates of the point on the back of participant's body (roughly on the 7th cervical vertebrae; used as a reference point)
-   *samplingRate*: sampling rate of the motion capture system
-   *TimeMaxLip*: time stamp of the maximal lip distance
-   *LipDist*: maximal lip distance within the vowel interval in centimeters (markers were placed on top of the upper and below the lower lip)

# Beginning of analysis

Here begins the actual data analysis.

## Data preparation

Calculate distances in 3D:

```{r distances, echo=TRUE, message=FALSE, warning=FALSE}
can <- mutate(can,
              dist.mg.f.3d = sqrt((x_f_mean - x_mg_mean)^2 + (y_f_mean - y_mg_mean)^2 + (z_f_mean - z_mg_mean)^2), # mid glasses to front
              dist.f.c7.3d = sqrt((x_c7_mean - x_f_mean)^2 + (y_c7_mean - y_f_mean)^2 + (z_c7_mean - z_f_mean)^2), # front to back
              dist.c7.mg.3d = sqrt((x_mg_mean - x_c7_mean)^2 + (y_mg_mean - y_c7_mean)^2 + (z_mg_mean - z_c7_mean)^2)) # back to mid glasses
```

Calculate angles in 3D:

```{r angles, echo=TRUE, message=FALSE, warning=FALSE}
can <- mutate(can,
              angle.mg.3d = acosd((dist.c7.mg.3d^2 + dist.mg.f.3d^2 - dist.f.c7.3d^2) / (2 * dist.c7.mg.3d * dist.mg.f.3d)), # mid glasses
              angle.f.3d = acosd((dist.mg.f.3d^2 + dist.f.c7.3d^2 - dist.c7.mg.3d^2) / (2 * dist.mg.f.3d * dist.f.c7.3d)), # front
              angle.c7.3d = acosd((dist.f.c7.3d^2 + dist.c7.mg.3d^2 - dist.mg.f.3d^2) / (2 * dist.f.c7.3d * dist.c7.mg.3d))) # back -- I use this one as this is the most stable point on the body
```

Select only necessary columns and rename them:

```{r}
can <- can %>%
  mutate(
    f0_range = max_f0 - min_f0,
    y_mg_mean = y_mg_mean*100
    ) %>%
  select(
    subject, part, size, v.pos, h.pos, text, start, duration, 
    overall_dB, f0_range, mean_f0, X50_F1, X50_F2, X50_F3, 
    height, dataset, y_mg_mean, LipDist, angle.c7.3d
    ) %>%
  rename(
    speaker = subject,
    can_size = size,
    v_pos = v.pos,
    h_pos = h.pos,
    vowel = text,
    dB_mean = overall_dB,
    f0_mean = mean_f0,
    F1 = X50_F1,
    F2 = X50_F2,
    F3 = X50_F3,
    head_pos = y_mg_mean,
    angle = angle.c7.3d,
    lip_dist = LipDist) 
```

Look at the data now:

```{r}
can
```

## Remove measure errors

We do not remove outliers, as they may be valuables data points. However, we should remove erroneous measurements.

With speaker 16, we forgot to turn on the right microphone, therefore, the data is not trustworthy and we are forced to remove it.

```{r}
can <- subset(can, speaker != '16')
```

Pätzold and Simpson ([1997, 225](https://www.ipds.uni-kiel.de/kjk/pub_exx/aipuk32/mpas.pdf)) give the following formant values in read speach of female speakers for the vowels in question:

|     |                |                   |                   |
|-----|----------------|-------------------|-------------------|
|     | F1             | F2                | F3                |
| [ɪ] | 391 (350--442) | 2136 (1905--2348) | 2867 (2660--3026) |
| [a] | 751 (651--838) | 1460 (1346--1583) | 2841 (2679--2983) |

We decided to group the data per participant and per vowel and, within the grouped data, remove outliers individually for *f*0 range, *f*0 mean, *f*1, *f*2, and *f*3.

```{r}
# Columns to process
columns_to_process <- c("dB_mean", "f0_range", "f0_mean", "F1", "F2", "F3")

# Group by Language and Participant and then loop through each column
can_grouped <- can %>%
  group_by(speaker, vowel) %>%
  mutate(across(all_of(columns_to_process), .fns = ~{
    cat("Processing column:", deparse(substitute(.)), "\n")
    
    # Calculate IQR
    Q1 <- quantile(.x, 0.25, na.rm = TRUE)
    Q3 <- quantile(.x, 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    
    # Define lower and upper bounds for outliers
    lower_bound <- Q1 - 2 * IQR
    upper_bound <- Q3 + 2 * IQR
    
    # Identify outliers
    outliers <- .x < lower_bound | .x > upper_bound
    
    # Replace outliers with NA
    .x[outliers] <- NA
    .x
  })) %>% 
  ungroup()
```

Check how the outlier removal impacted the data. First, the amount of NAs.

```{r}
# Combine the results into a data frame
na_summary_phon <- data.frame(
  NA_Count_Pre_Removal = colSums(is.na(can[, columns_to_process])),
  NA_Count_Post_Removal = colSums(is.na(can_grouped[, columns_to_process])),
  NA_Perc_Pre_Removal = (colSums(is.na(can[, columns_to_process])) / nrow(can)) * 100,
  NA_Perc_Post_Removal = (colSums(is.na(can_grouped[, columns_to_process])) / nrow(can_grouped)) * 100
)

na_summary_phon
```

Then, look at the means. When looking at the table, it's best to sort by speaker to see where there was a change.

```{r}
# Calculate means for each variable in the pre-removal dataset
means_can <- can %>%
  group_by(speaker, vowel) %>%
  summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>% 
  ungroup()

# Calculate means for each variable in the post-removal dataset
means_can_grouped <- can_grouped %>%
  group_by(speaker, vowel) %>%
  summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>% 
  ungroup()

# Combine the means into a single summary table
outlier_summary_acc <- bind_rows(
  tibble(Variable = "Pre-Removal", means_can),
  tibble(Variable = "Post-Removal", means_can_grouped)
)
```

After inspecting the outlier removal, change the name back to can and remove the unnecessary data frames.

```{r}
can <- can_grouped
rm(can_grouped, means_can, means_can_grouped)
rm(columns_to_process)
```

We will do the same, but for the kinematic variables. Here, we will only group by speaker.

```{r}
# Columns to process
columns_to_process <- c("head_pos", "angle", "lip_dist")

# Group by Language and Participant and then loop through each column
can_grouped <- can %>%
  group_by(speaker) %>%
  mutate(across(all_of(columns_to_process), .fns = ~{
    cat("Processing column:", deparse(substitute(.)), "\n")
    
    # Calculate IQR
    Q1 <- quantile(.x, 0.25, na.rm = TRUE)
    Q3 <- quantile(.x, 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    
    # Define lower and upper bounds for outliers
    lower_bound <- Q1 - 2 * IQR
    upper_bound <- Q3 + 2 * IQR
    
    # Identify outliers
    outliers <- .x < lower_bound | .x > upper_bound
    
    # Replace outliers with NA
    .x[outliers] <- NA
    .x
  })) %>% 
  ungroup()
```

Check how the outlier removal impacted the data. First, the amount of NAs.

```{r}
# Combine the results into a data frame
na_summary_kin <- data.frame(
  NA_Count_Pre_Removal = colSums(is.na(can[, columns_to_process])),
  NA_Count_Post_Removal = colSums(is.na(can_grouped[, columns_to_process])),
  NA_Perc_Pre_Removal = (colSums(is.na(can[, columns_to_process])) / nrow(can)) * 100,
  NA_Perc_Post_Removal = (colSums(is.na(can_grouped[, columns_to_process])) / nrow(can_grouped)) * 100
)

na_summary_kin
```

Then, look at the means. When looking at the table, it's best to sort by speaker to see where there was a change.

```{r}
# Calculate means for each variable in the pre-removal dataset
means_can <- can %>%
  group_by(speaker) %>%
  summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>% 
  ungroup()

# Calculate means for each variable in the post-removal dataset
means_can_grouped <- can_grouped %>%
  group_by(speaker) %>%
  summarise(across(all_of(columns_to_process), mean, na.rm = TRUE)) %>% 
  ungroup()

# Combine the means into a single summary table
outlier_summary_kin <- bind_rows(
  tibble(Variable = "Pre-Removal", means_can),
  tibble(Variable = "Post-Removal", means_can_grouped)
)
```

After inspecting the outlier removal, change the name back to can and remove the unnecessary data frames.

```{r}
can <- can_grouped
rm(can_grouped, means_can, means_can_grouped)
rm(columns_to_process)
```


## Adding z-scores for plotting

### Phonetic variables

```{r, message = FALSE}
# Create tibble with means and sd per speaker and vowel:
can %>%
  na.omit() %>%
  group_by(speaker, vowel) %>%
  summarize_at(vars(dB_mean, f0_mean, f0_range, F1, F2, F3), list(mean = mean, sd = sd)) %>%
  ungroup() %>%
  {. ->> speakers_phon}

# Join tibble with means per speaker and vowel
can <- can %>%
  left_join(speakers_phon, by = c("speaker", "vowel")) %>%
  # Calculate z-scores
  mutate(
    db_mean_z = (dB_mean - dB_mean_mean) / dB_mean_sd,
    f0_mean_z = (f0_mean - f0_mean_mean) / f0_mean_sd,
    f0_range_z = (f0_range - f0_range_mean) / f0_range_sd,
    F1_z = (F1 - F1_mean) / F1_sd,
    F2_z = (F2 - F2_mean) / F2_sd,
    F3_z = (F3 - F3_mean) / F3_sd
  ) %>%
  # Deselect unneeded variables
  select(-c(
    dB_mean_sd, dB_mean_mean,
    f0_mean_sd, f0_mean_mean,
    f0_range_sd, f0_range_mean,
    F1_sd, F1_mean,
    F2_sd, F2_mean,
    F3_sd, F3_mean
  ))
```

### Kinematic variables

```{r, message = FALSE}
# Create tibble with means and sd per speaker and vowel for head_pos, lip_dist, and angle:
can %>%
  na.omit() %>%
  group_by(speaker, vowel) %>%
  summarize_at(vars(head_pos, lip_dist, angle), list(mean = mean, sd = sd)) %>%
  ungroup() %>%
  {. ->> speakers_kin}

# Join tibble with means per speaker and vowel
can <- can %>%
  left_join(speakers_kin, by = c("speaker", "vowel")) %>%
  # Calculate z-scores
  mutate(
    head_pos_z = (head_pos - head_pos_mean) / head_pos_sd,
    lip_dist_z = (lip_dist - lip_dist_mean) / lip_dist_sd,
    angle_z = (angle - angle_mean) / angle_sd
  ) %>%
  # deselect unneeded variables
  select(-c(
    head_pos_sd, head_pos_mean,
    lip_dist_sd, lip_dist_mean,
    angle_sd, angle_mean
  ))
```

## Group movers

People differ in the SD of the head position and thus head angle. This suggests there are some who move their head more, and some who move their head less.

The idea is to group speakers into movers and non-movers by looking at the SD of the mean head position:

```{r}
can %>% 
  group_by(speaker) %>%
  summarize_at(vars(head_pos), list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))) %>% 
  {. ->> speakers_pos} %>% 
  ungroup() %>% 
  print(n = Inf)
```

Check mean of SD to estimate point of division:

```{r}
mean(speakers_pos$sd)
```

Group of movers with SD above 1.12:

```{r}
filter(speakers_pos, sd > 1.123773)
```

N = 13

Group of non-movers with SD below 1.12:

```{r}
filter(speakers_pos, sd < 1.123773)
```

N = 17

Add a categorical variable mover/non-mover:

```{r, message = FALSE}
can <- left_join(can,
                 can %>% 
                   group_by(speaker) %>%
                   summarize_at(vars(head_pos),
                                list(mean_pos = ~ mean(., na.rm = TRUE),
                                     sd_pos = ~ sd(., na.rm = TRUE)),
                                na.rm = TRUE) %>% 
                   mutate(mover = ifelse(sd_pos < 1.123773, 'no', 'yes')) %>%
                   ungroup())
```

Calculate the difference between the actual angle and the speaker's mean to plot it later:

```{r}
can <- can %>% 
  mutate(pos_difference = head_pos - mean_pos) %>% 
  select(-c(sd_pos, mean_pos)) # deselect unneded variables
```

## Prepare formants

### Transform to bark

NAs are problematic for phonR, therefore I'm replacing them with a placeholder value

```{r}
can_noNA <- can %>%
  mutate(across(c(F1, F2, F3), ~ifelse(is.na(.), 9999, .)))
```

Add bark (= another type of normalized scale) values for formants

```{r}
can_noNA <- mutate(can_noNA,
              F1_bark = normBark(F1),
              F2_bark = normBark(F2),
              F3_bark = normBark(F3))
```

Replace back the placeholder value with NAs for formants in herzt and also replace the respective cells of formants transofrmed to bark to NA.

```{r}
can_noNA <- mutate(can_noNA,
                    across(c(F1, F2, F3), ~ifelse(. == 9999, NA, .)),
                    across(c(F1_bark, F2_bark, F3_bark), 
                           ~ifelse(is.na(get(substring(cur_column(), 1, 2))), NA, .)))

can <- can_noNA
rm(can_noNA)
```

### Calculate distances

We have to create a data frame where can sizes are aside each other for each condition to be able to calculate the distances.

```{r}
# Pivot the data to create separate columns for each variable and category
can_formants_aside <- can %>%
  pivot_wider(
    id_cols = c(speaker, vowel, v_pos, h_pos),
    names_from = can_size,
    values_from = c(F1, F2, F3, lip_dist, F1_z, F2_z, F3_z, F1_bark, F2_bark, F3_bark),
    names_sep = "_"
  ) %>%
  # Rename columns for clarity
  rename(
    F1_large = F1_large,
    F1_small = F1_small,
    F2_large = F2_large,
    F2_small = F2_small,
    F3_large = F3_large,
    F3_small = F3_small,
    lip_dist_large = lip_dist_large,
    lip_dist_small = lip_dist_small,
    F1_z_large = F1_z_large,
    F1_z_small = F1_z_small,
    F2_z_large = F2_z_large,
    F2_z_small = F2_z_small,
    F3_z_large = F3_z_large,
    F3_z_small = F3_z_small,
    F1_bark_large = F1_bark_large,
    F1_bark_small = F1_bark_small,
    F2_bark_large = F2_bark_large,
    F2_bark_small = F2_bark_small,
    F3_bark_large = F3_bark_large,
    F3_bark_small = F3_bark_small
  )

# View the resulting dataframe
print(can_formants_aside)
```

Calculate Euclidean distance between large and small can formants in the same condition:

```{r}
can_formants_aside <- mutate(can_formants_aside,
  dist_size_hz = sqrt((F1_large - F1_small)^2 + (F2_large - F2_small)^2),
  dist_size_z = sqrt((F1_z_large - F1_z_small)^2 + (F2_z_large - F2_z_small)^2),
  dist_size_bark = sqrt((F1_bark_large - F1_bark_small)^2 + (F2_bark_large - F2_bark_small)^2)
)
```

## Contrast-code

Contrast code vowel, can_size, and mover (the latter just in case) and store as separate vectors:

```{r}
can <- can %>%
  mutate(
    vowel_s = if_else(vowel == "I", -0.5, 0.5),
    can_size_s = if_else(can_size == "small", -0.5, 0.5),
    mover_s = if_else(mover == "no", -0.5, 0.5)
  )
```


# Initial descriptive statistics

How many speakers?

```{r}
length(unique(can$speaker))
```

How many unique realizations per speaker?

```{r}
can %>%
  group_by(speaker) %>%
  summarize(num_unique_realizations = n_distinct(paste(can_size, v_pos, h_pos, vowel))) %>%
  ungroup() %>%
  print(n = 30)
```

NAs in variables per speaker.

```{r}
can %>%
  group_by(speaker) %>%
  summarize(
    across(c(dB_mean, f0_mean, f0_range, F1, F2, F3, head_pos, lip_dist, angle),
           ~sum(is.na(.))),
    .groups = 'drop'
  ) %>%
  print(n = 30)
```

Because each participant had a total of 100 trials, these values are also percentages. There is quite some imbalance in the missing values. It's worth to keep that in mind and definitely allow for individual variance by speaker in the model.

Check means of phonetic variables per speaker:

```{r}
print(speakers_phon, n = 60)
```

Check means of kinematic variables per speaker:

```{r}
print(speakers_kin, n = 60)
```

# Export dataset

Let's export the csv. 

```{r}
write.csv(can, paste0(data, "can.csv"), row.names = FALSE)
```


# Head position

Here, I will start separating the two analyses for clarity purposes. We begin with the first hypothesis that proposes that fundamental frequency is influenced by head position, specifically, that the more upward the head is rotated, the higher the fundamental frequency.

## Head position vs. angle

While head position is unidimensional, angle covers movement across three dimensions. We have to choose which of them we will take for the analysis.

First, let's check their correlation in classical terms.

```{r}
cor.test(can$angle, can$head_pos)
# what will happen if we use z-normalized values
cor.test(can$angle_z, can$head_pos_z)
# the correlation skyrocketed! but it was there anyway
```

Plotting the raw values...

```{r}
ggplot(can,
       aes(x = head_pos,
           y = angle)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = F)
```

and now the z-scored.

```{r}
ggplot(can,
       aes(x = head_pos_z,
           y = angle_z)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = F)
```

So we cannot use both, but pick one. I am logically tending to pick angle because of larger dimensionality. However, higher dimensionality introduces degrees of freedom.

```{r}
# Plot for head_pos vs f0_mean_z
f0_head_pos <- ggplot(can,
       aes(x = f0_mean_z,
           y = head_pos_z)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = FALSE) +
  labs(title = "Head position vs f0 mean")

# Plot for angle vs f0_mean_z
f0_angle <- ggplot(can,
       aes(x = f0_mean_z,
           y = angle_z)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = FALSE) +
  labs(title = "Angle vs f0 mean")

# Arrange plots side by side
grid.arrange(f0_head_pos, f0_angle, ncol = 2)
```

Visually, they are basically the same. I think it is better to go with head position then, because it captures exactly the movement of interest.

## Head position vs. vertical position

Logically, the vertical position would induce movement. It does not do it always, but if we put two highly correlated factors in the analysis, this may confuse the model and the effects may be diluted.

Therefore, we check for the correlation between head position and vertical position.

```{r}
cor.test(can$head_pos, can$v_pos)
# what will happen if we use z-normalized values
cor.test(can$head_pos_z, can$v_pos)
```

Plotting the raw values...

```{r}
ggplot(can,
       aes(x = v_pos,
           y = head_pos)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = F)
```

Given the correlation, we should not put them in the same model. We will have to separate them and see how they perform in the same environment.

## Bayesian modeling

Here, I'm computing a model that estimates the probability of an effect of head position (among others) on *f*0. The first iteration of this analysis was done with the help of Timo Roettger. Since then, however, the analysis has been upgraded with the comments of three anonymous reviewers and Bodo Winter.

------------------------------------------------------------------------

### Priors

We can expect *f*0 **not** to be normally distributed. However, if we use some kind of normalization for the outcome variable, like z-scoring, we cannot fit group-level effects by participant (thanks for this insight to Stefano Coretta!). I will use a lognormal family for the model. Therefore, we must think of the priors on the log scale.

We will fit an intercept-only model for comparison, a model without random slopes and intercepts, and a maximal model. First, we inspect the priors we must specify for each model. Then, we will specify the priors separately.

For each model, I will fit weakly informative priors.

#### Intercept-only

```{r}
get_prior(formula = f0_mean ~ 1,
          data = can,
          family = lognormal())
```

Let's find a weakly informative prior

```{r}
# If we assume that the mean for f0 is 200
log(200)

# If we set the prior to normal(0,1), what would be the boundaries
exp(log(200)-0.5); exp(log(200)+0.5)

# If we set the prior to normal(0,2), what would be the boundaries
exp(log(200)-1); exp(log(200)+1)

# If we set the prior to normal(0,3), what would be the boundaries
exp(log(200)-1.5); exp(log(200)+1.5)

# I think that for (0,3) we can safely assume to respect all datapoints. This will be the prior we choose for the intercept.
```

Define priors for the intercept-only model

```{r}
priors_intOnlyH1 <- c(
  prior('normal(0, 3)', class = 'Intercept')
)
```

#### No random slopes

```{r}
get_prior(formula = f0_mean ~ 1 + vowel_s + can_size_s + head_pos + h_pos + v_pos + height + # angle and v_pos will be separated
            (1 | speaker),
          data = can,
          family = lognormal())
```

We don't have specific predictions about the magnitude of the specific effects. Most importantly we do not want to constrain any possible effect.

```{r}
priors_noRandomH1 <- c(
  prior('normal(0, 3)', class = 'Intercept'),
  prior('normal(0, 1)', class = b)
)
```

#### Maximal model

```{r}
get_prior(formula = f0_mean ~ 1 + vowel_s + can_size_s + head_pos + h_pos + v_pos + height + # head_pos and v_pos will be separated
            (1 + vowel_s + can_size_s + head_pos + h_pos + v_pos || speaker),
          data = can,
          family = lognormal())
```

I will not specify any priors for the group-level effects.

```{r}
priors_maxH1 <- c(
  prior('normal(0, 3)', class = 'Intercept'),
  prior('normal(0, 1)', class = b)
)
```

### Fit models

#### Intercept-only

```{r}
mdl_intOnlyH1 <- brm(f0_mean ~ 1,
                   data = can,
                   prior = priors_intOnlyH1,
                   family = lognormal(),
                   #backend = "cmdstanr", # depends on you
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_intOnlyH1.rds"))

# if we need to compress the model more
#saveRDS(mdl_intOnlyH1, file = paste0(models, "mdl_intOnlyH1.rds"), compress = "xz")

mdl_intOnlyH1 <- readRDS(paste0(models, "mdl_intOnlyH1.rds"))
```

Let's check how it looks like.

```{r}
summary(mdl_intOnlyH1)
```

```{r}
plot(mdl_intOnlyH1)
```

```{r}
pp_check(mdl_intOnlyH1, ndraws = 100)
```

The pp_check shows a slight right-skew and a "bump" around 200 Hz in the raw data which the model does not really respect.

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_intOnlyH1_loo.rds"))) {
  mdl_intOnlyH1_loo <- readRDS(paste0(models, "mdl_intOnlyH1_loo.rds"))
} else {
  mdl_intOnlyH1_loo <- loo(mdl_intOnlyH1)
  saveRDS(mdl_intOnlyH1_loo, paste0(models, "mdl_intOnlyH1_loo.rds"))
}
```

Check the loo.

```{r}
mdl_intOnlyH1_loo
```

#### No random slopes

##### Head position

```{r}
mdl_noRandomH1_headPos <- brm(f0_mean ~ 1 + vowel_s + can_size_s + 
                      head_pos + h_pos + height +
                      (1 | speaker),
                   data = can,
                   prior = priors_noRandomH1,
                   family = lognormal(),
                   backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 997,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_noRandomH1_headPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_noRandomH1_headPos, file = paste0(models, "mdl_noRandomH1_headPos.rds"), compress = "xz")

mdl_noRandomH1_headPos <- readRDS(paste0(models, "mdl_noRandomH1_headPos.rds"))
```

Let's check how it looks like.

```{r}
summary(mdl_noRandomH1_headPos)
```

```{r}
plot(mdl_noRandomH1_headPos)
```

```{r}
conditional_effects(mdl_noRandomH1_headPos, sample_prior = "only")
```

```{r}
pp_check(mdl_noRandomH1_headPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_noRandomH1_headPos_loo.rds"))) {
  mdl_noRandomH1_headPos_loo <- readRDS(paste0(models, "mdl_noRandomH1_headPos_loo.rds"))
} else {
  mdl_noRandomH1_headPos_loo <- loo(mdl_noRandomH1_headPos)
  saveRDS(mdl_noRandomH1_headPos_loo, paste0(models, "mdl_noRandomH1_headPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_noRandomH1_headPos_loo
```

##### Vertical position

```{r}
mdl_noRandomH1_vPos <- brm(f0_mean ~ 1 + vowel_s + can_size_s + 
                      h_pos + v_pos + height +
                      (1 | speaker),
                   data = can,
                   prior = priors_noRandomH1,
                   family = lognormal(),
                   #backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_noRandomH1_vPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_noRandomH1_vPos, file = paste0(models, "mdl_noRandomH1_vPos.rds"), compress = "xz")

mdl_noRandomH1_vPos <- readRDS(paste0(models, "mdl_noRandomH1_vPos.rds"))
```

Let's check how it looks like.

```{r}
summary(mdl_noRandomH1_vPos)
```

```{r}
plot(mdl_noRandomH1_vPos)
```

```{r}
conditional_effects(mdl_noRandomH1_vPos, sample_prior = "only")
```

```{r}
pp_check(mdl_noRandomH1_vPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_noRandomH1_vPos_loo.rds"))) {
  mdl_noRandomH1_vPos_loo <- readRDS(paste0(models, "mdl_noRandomH1_vPos_loo.rds"))
} else {
  mdl_noRandomH1_vPos_loo <- loo(mdl_noRandomH1_vPos)
  saveRDS(mdl_noRandomH1_vPos_loo, paste0(models, "mdl_noRandomH1_vPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_noRandomH1_vPos_loo
```

#### Maximal model

##### Head position

```{r}
mdl_maxH1_headPos <- brm(f0_mean ~ 1 + vowel_s + can_size_s + 
                      head_pos + h_pos + height +
                      (1 + vowel_s + can_size_s + 
                         head_pos + h_pos || speaker),
                   data = can,
                   prior = priors_maxH1,
                   family = lognormal(),
                   backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_maxH1_headPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_maxH1_headPos, file = paste0(models, "mdl_maxH1_headPos.rds"), compress = "xz")

mdl_maxH1_headPos <- readRDS(paste0(models, "mdl_maxH1_headPos.rds"))

beepr::beep()
```

Let's check how it looks like.

```{r}
summary(mdl_maxH1_headPos)
```

```{r}
plot(mdl_maxH1_headPos)
```

```{r}
conditional_effects(mdl_maxH1_headPos, sample_prior = "only")
```

```{r}
pp_check(mdl_maxH1_headPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_maxH1_headPos_loo.rds"))) {
  mdl_maxH1_headPos_loo <- readRDS(paste0(models, "mdl_maxH1_headPos_loo.rds"))
} else {
  mdl_maxH1_headPos_loo <- loo(mdl_maxH1_headPos, moment_match = TRUE)
  saveRDS(mdl_maxH1_headPos_loo, paste0(models, "mdl_maxH1_headPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_maxH1_headPos_loo
```

See if any [reloo](https://paul-buerkner.github.io/brms/reference/reloo.html) is needed.

```{r}
if (file.exists(paste0(models, "mdl_maxH1_headPos_reloo.rds"))) {
  mdl_maxH1_headPos_reloo <- readRDS(paste0(models, "mdl_maxH1_headPos_reloo.rds"))
} else {
  mdl_maxH1_headPos_reloo <- reloo(mdl_maxH1_headPos_loo, mdl_maxH1_headPos, chains = 1)
  saveRDS(mdl_maxH1_headPos_reloo, paste0(models, "mdl_maxH1_headPos_reloo.rds"))
}

mdl_maxH1_headPos_reloo
```

##### Vertical position

```{r}
mdl_maxH1_vPos <- brm(f0_mean ~ 1 + vowel_s + can_size_s + 
                      h_pos + v_pos + height +
                      (1 + vowel_s + can_size_s + 
                         h_pos + v_pos || speaker),
                   data = can,
                   prior = priors_maxH1,
                   family = lognormal(),
                   #backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_maxH1_vPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_maxH1_vPos, file = paste0(models, "mdl_maxH1_vPos.rds"), compress = "xz")

mdl_maxH1_vPos <- readRDS(paste0(models, "mdl_maxH1_vPos.rds"))

beepr::beep()
```

Let's check how it looks like.

```{r}
summary(mdl_maxH1_vPos)
```

```{r}
plot(mdl_maxH1_vPos)
```

```{r}
conditional_effects(mdl_maxH1_vPos, sample_prior = "only")
```

```{r}
pp_check(mdl_maxH1_vPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_maxH1_vPos_loo.rds"))) {
  mdl_maxH1_vPos_loo <- readRDS(paste0(models, "mdl_maxH1_vPos_loo.rds"))
} else {
  mdl_maxH1_vPos_loo <- loo(mdl_maxH1_vPos, moment_match = TRUE)
  saveRDS(mdl_maxH1_vPos_loo, paste0(models, "mdl_maxH1_vPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_maxH1_vPos_loo
```

See if any [reloo](https://paul-buerkner.github.io/brms/reference/reloo.html) is needed.

```{r}
if (file.exists(paste0(models, "mdl_maxH1_vPos_reloo.rds"))) {
  mdl_maxH1_vPos_reloo <- readRDS(paste0(models, "mdl_maxH1_vPos_reloo.rds"))
} else {
  mdl_maxH1_vPos_reloo <- reloo(mdl_maxH1_vPos_loo, mdl_maxH1_vPos, chains = 1)
  saveRDS(mdl_maxH1_vPos_reloo, paste0(models, "mdl_maxH1_vPos_reloo.rds"))
}

mdl_maxH1_vPos_reloo
```

#### Model comparison

We computed a set of models from integer only, to a maximal model. We will compare them now, but still adhereing to head position vs. vertical position separately. 

##### Head position models

```{r}
compH1_headPos <- loo_compare(mdl_noRandomH1_headPos_loo,mdl_maxH1_headPos_reloo)
compH1_headPos
```

As expected, the maximal model is the best estimate. We will proceed with extracting the effects from this model.

##### Vertical position models

```{r}
compH1_vPos <- loo_compare(mdl_intOnlyH1_loo,mdl_noRandomH1_vPos_loo,mdl_maxH1_vPos_reloo)
compH1_vPos
```

As expected, the maximal model is the best estimate. We will proceed with extracting the effects from this model.

### Analysis of best-fit models

We found that the best-fit models are the maximal models. Now we will extract the predictions from the models.

#### Head-position

We would expect:

- vowel_s to have a negative effect on f0_mean, because -0.5 is [i], and 0.5 is [a], and [i] should have higher intrinsic *f*0
- head_pos to have a positive effect on f0_mean, because with increasing head_pos we raise that *f*0 
- height might have a negative effect on f0_mean, because taller people might have lower *f*0
- can_size_s might have a negative effect on f0_mean, because -0.5 is small, and 0.5 is large, and small might induce higher *f*0 (but this is speculative)
- h_pos might have a positive effect on f0_mean, because of the musical SNARC effect and the keys on the keyboard being low on the left and high on the right, so going from 1 to 5 *f*0 could increase (but this is speculative)

First, let's look at the summary again.

```{r}
summary(mdl_maxH1_headPos)
```

Now let's check the hypotheses using brms function.

```{r}
hypothesis(mdl_maxH1_headPos, "vowel_s < 0")
plot(hypothesis(mdl_maxH1_headPos, "vowel_s < 0"))
```

The assumption holds for vowel: [i] has a higher means *f*0.

```{r}
hypothesis(mdl_maxH1_headPos, "head_pos > 0")
plot(hypothesis(mdl_maxH1_headPos, "head_pos > 0"))
```

The assumption holds for head_pos: upward head movement induces an increas in *f*0.

```{r}
hypothesis(mdl_maxH1_headPos, "height < 0")
plot(hypothesis(mdl_maxH1_headPos, "height < 0"))
```

The assumption does hold for height in our data: taller participants tend to have lower *f*0 means in vowel intervals.

```{r}
hypothesis(mdl_maxH1_headPos, "can_size_s < 0")
plot(hypothesis(mdl_maxH1_headPos, "can_size_s < 0"))
```

The assumption does not hold for can_size in our data: larger cans do not generally induce higher *f*0 means in vowel intervals.

```{r}
hypothesis(mdl_maxH1_headPos, "h_pos > 0")
plot(hypothesis(mdl_maxH1_headPos, "h_pos > 0"))
```

The assumption does not hold for h_pos in our data: an increase in the horizontal position from left to right does not generally induce higher *f*0 means in vowel intervals.

That is generally super exciting and means that our hypothesis checks out! Head position has an effect on the *f*0 mean.

Change to report:

```{r}
summary(can$head_pos) # the unit is centimeters

exp(fixef(mdl_maxH1_headPos))
# This is giving the original scale for the intercept but odds for coefficients

exp(fixef(mdl_maxH1_headPos)[1,1]) # intercept in Hz
(exp(fixef(mdl_maxH1_headPos)[1,1])*exp(fixef(mdl_maxH1_headPos)[4,1]))-exp(fixef(mdl_maxH1_headPos)[1,1]) # estimate head_pos in Hz (positive)
(exp(fixef(mdl_maxH1_headPos)[1,1])*exp(fixef(mdl_maxH1_headPos)[2,1]))-exp(fixef(mdl_maxH1_headPos)[1,1]) # estimate vowel_s in Hz (negative)
```

All hypotheses tested together:

```{r}
hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
```


#### Vertical position

We expect the other effects to be the same, except for:

- v_pos should have a negative effect on f0_mean, because position 1 is on the top and 5 is on the bottom, thus, with increasing v_pos, *f*0 should decrease

First, let's look at the summary again.

```{r}
summary(mdl_maxH1_vPos)
```

Now let's check the hypotheses using brms function.

```{r}
hypothesis(mdl_maxH1_vPos, "vowel_s < 0")
plot(hypothesis(mdl_maxH1_vPos, "vowel_s < 0"))
```

The assumption holds for vowel: [i] has a higher means *f*0.

```{r}
hypothesis(mdl_maxH1_vPos, "v_pos < 0")
plot(hypothesis(mdl_maxH1_vPos, "v_pos < 0"))
```

The assumption holds for head_pos: upward head movement induces an increas in *f*0.

```{r}
hypothesis(mdl_maxH1_vPos, "height < 0")
plot(hypothesis(mdl_maxH1_vPos, "height < 0"))
```

The assumption does not hold for height in our data: higher participants do not generally have higher *f*0 means in vowel intervals.

```{r}
hypothesis(mdl_maxH1_vPos, "can_size_s < 0")
plot(hypothesis(mdl_maxH1_vPos, "can_size_s < 0"))
```

The assumption does not hold for can_size in our data, but it is by a thread!: larger cans do not generally induce higher *f*0 means in vowel intervals.

```{r}
hypothesis(mdl_maxH1_vPos, "h_pos > 0")
plot(hypothesis(mdl_maxH1_vPos, "h_pos > 0"))
```

The assumption does not hold for h_pos in our data: an increase in the horizontal position from left to right does not generally induce higher *f*0 means in vowel intervals.

Therefore, we also see an effect of vertical position on *f*0 mean.

Change to report:

```{r}
summary(can$v_pos)

exp(fixef(mdl_maxH1_vPos))

exp(fixef(mdl_maxH1_vPos)[1,1]) # intercept in Hz
(exp(fixef(mdl_maxH1_vPos)[1,1])*exp(fixef(mdl_maxH1_vPos)[4,1]))-exp(fixef(mdl_maxH1_vPos)[1,1]) # estimate v_pos in Hz (positive)
(exp(fixef(mdl_maxH1_vPos)[1,1])*exp(fixef(mdl_maxH1_vPos)[2,1]))-exp(fixef(mdl_maxH1_vPos)[1,1]) # estimate vowel_s in Hz (negative)
```

All hypotheses tested together:

```{r}
hypothesis(mdl_maxH1_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
```


----

#### Summary

Taken together, we see that in both models, vowel has a reliable effect, which is our logical control. Importantly, our hypothesis holds, we find a reliable effect of head position on *f*0, whereby each 1 cm change in the predictor induces 1 Hz change in the outcome variable. This really is something, given the range of head movement within speaker.

```{r}
can %>%
  group_by(speaker) %>%
  summarize(head_range = max(head_pos, na.rm = TRUE) - min(head_pos, na.rm = TRUE)) %>%
  ungroup() %>%
  {. ->> head_range} %>%
  print(n = 30)
```

Given the various head movement behavior, we can also expect big inter-speaker variance.

```{r}
# brmstools::forest(mdl_maxH1_headPos, 
#                   grouping = "speaker", 
#                   pars = "head_pos", 
#                   digits = 0,
#                   sort = T)

# See new way:
# https://github.com/mvuorre/brmstools?tab=readme-ov-file#forest-plots
```

The effect is present across all speakers. It would be nice to see how this relates to being mover or non-mover.

```{r}
p_hPos_mover <- mdl_maxH1_headPos %>%
  spread_draws(b_Intercept, b_head_pos, r_speaker[speaker,term]) %>%
  filter(term == "head_pos") %>% 
  mutate(mu = b_head_pos + r_speaker) %>% 
  ungroup() %>%
  mutate(speaker = str_replace_all(speaker, "[.]", " ")) %>%
  mutate(speaker = as.double(speaker)) %>% 
  left_join(can %>% select(speaker, mover), by = "speaker") %>%
  ggplot(aes(x = mu, y = reorder(speaker, mu), fill = mover)) +
    geom_halfeyeh(.width = .5, size = 2/3, alpha = 0.5) +  # Adjusted alpha for fill color
    scale_fill_manual(values = colorBlindBlack8) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "grey") +  # Grey dashed line at 0
    labs(x = "Posterior distribution (Head position)", y = "Speaker", fill = "Mover") +
    theme_minimal()

p_hPos_mover

ggsave(file = paste0(plots, "p_hPos_mover.pdf"), plot = p_hPos_mover, width = 10, height = 8)

# this is very memory-consuming, so run this to kind of "reset"
gc()

```

This shows that being a mover has nothing to do with the effect. Person 7 shows the strongest effect and she is a mover, but person 2 is not a mover and her effect is second. So the effect is equally strong in people, who move less.


We had to separate head position and vertical position due to their correlation and calculate separate models. The effect of vertical position that we found is reliable, but translated to real-world terms, much weaker. For 1 step change in vertical position, we find roughly 1 Hz change. But since our plane only comprised of 5 steps, which were projected on the surface of 1,30 meters, this is much weaker an effect than we exposed for head position.

Most likely, the effect we find for vertical position is the one induced through head movement --HOW to show?

## Plots

Having raw and posterior values, we can show the effects visually.

### Head position

Scatter plot with regression lines: *f*0 mean x head position

Z-normalized

```{r}
ggplot(can, aes(x = head_pos_z, y = f0_mean_z, color = factor(vowel))) +
    geom_point(alpha = 0.5) +
    stat_smooth(method = "lm", se = TRUE) +
    labs(color = "Vowel", x = "Head Position (z-normalized)", y = "f0 Mean (z-normalized)") +
    theme_minimal() +
    scale_color_manual(values = colorBlindBlack8)
```

Raw values

```{r}
ggplot(can, aes(x = head_pos, y = f0_mean, color = factor(vowel))) +
    geom_point(alpha = 0.5) +
    stat_smooth(method = "lm", se = TRUE) +
    labs(color = "Vowel", x = "Head Position (cm)", y = "f0 Mean (Hz)") +
    theme_minimal() +
    scale_color_manual(values = colorBlindBlack8)
```

There is a lot of individual differences between the speakers. E.g. 25 shows barely an effect for vowel and an opposite effect for size, especially striking in a; similarly 12 shows no effect for size and only a small for vowel; speakers 22 and 27 have a similar pattern of their behavior, in line also with 14 and 19.

Let's see how the movers behave:

```{r, warning=FALSE, message=FALSE}
print(f0_vowel + 
        facet_wrap(~mover) + 
        theme_minimal())
```



```{r, warning=FALSE, message=FALSE}
f0_head_pos <- ggplot(can,
                   aes(x = head_pos_z,
                       y = f0_mean_z,
                       color = can_size)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = F) +
  scale_color_manual(values=colorBlindBlack8) +
  labs(x = "Head position (z-normalized)",
       y = "F0 (z-normalized)",
       color = "Can size")

print(f0_head_pos + theme_bw() +
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 14,
                                        face = "bold"),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12)))

# ggsave(filename = "F0-head.pdf",
#        plot = last_plot(),
#        width = 7, height = 4)
```

#### Mover

```{r}
f0_head_mover <- ggplot(can,
       aes(x = head_pos_z,
           y = f0_mean_z)) +
    geom_point(alpha = 0.1) +
    geom_smooth(method = lm,
                size = 1,
                se = F,
                color = 'black') +
    #color = "#00BFC4") +
    facet_wrap(~mover, labeller = label_both) + 
    labs(x = "Head position (z-normalized)",
         y = "f0 mean (z-Normalized)")

print(f0_head_mover + theme_bw() +
        theme(strip.text.x = element_text(size = 12),
              #strip.background = element_rect(fill = "#F8766D"),
              axis.text = element_text(size = 12),
              axis.title = element_text(size = 14,
                                        face = "bold"),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12)))

# ggsave(filename = "F0-head-mover.pdf",
#         plot = last_plot(),
#         width = 7, height = 4)
```

#### F0 mean and vowel

```{r}
f0_vowel <- ggplot(can,
       aes(y = f0_mean,
           x = vowel,
           color = can_size)) +
    stat_summary(position = position_dodge(width = 0.5),
                 size = 0.75) +
    scale_color_manual(values=colorBlindBlack8)+
    labs(x = "Vowel",
         y = "F0 (z-normalized)",
         color = "Can size")

print(f0_vowel + 
        theme_bw()+
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 16),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12)))

```

The intrisic F0 difference between a and I is clearly visible with a having much lower F0 than I. Apart from that, we can see the effect of can size in both a and I, with large can yielding lower F0 than a small can.

Now let's see how this relationship looks like in all possible vertical and horizontal positions. I'm creating a 5x5 grid

```{r, warning=FALSE, message=FALSE}
print(f0_vowel + 
        facet_grid(v_pos~h_pos) + 
        theme_minimal())
```


The a is always lower than the I, but we can see that here the relationship between small and large can size is sometimes flipped to the general tendency in the plot above.

Let's have a look how the different speakers are behaving.

```{r, warning=FALSE, message=FALSE}
print(f0_vowel + 
        facet_wrap(~speaker) + 
        theme_minimal())
```


#### Posterior distribution

```{r}
# Extracting posterior samples 
post_maxH1_headPos <- mdl_maxH1_headPos %>% 
  gather_draws(b_vowel_s, b_can_size_s, b_head_pos, b_h_pos, b_height) 

# Plotting intervals with densities
postplot_maxH1_headPos <- 
  ggplot(post_maxH1_headPos, 
         aes(x = .value, y = .variable)) +
  stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
  geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
               linetype = "dashed", color = "grey", size = 1) + 
  theme_bw() +
  labs(x = "Posterior density", y = "Variable") +
  scale_y_discrete(labels = c("Can size", "Head position", "Height", "Horizontal pos.", "Vowel")) + # Must be in alphabetical order
  scale_x_continuous(limits = c(-0.12, 0.02))

postplot_maxH1_headPos
```




### Vertical position

Scatter plot with regression lines: *f*0 mean x vertical position

```{r}
ggplot(can, aes(x = v_pos, y = f0_mean, color = factor(vowel))) +
    geom_point(alpha = 0.5) +
    stat_smooth(method = "lm", se = TRUE) +
    labs(color = "Vowel", x = "Vertical Position", y = "f0 Mean (Hz)") +
    theme_minimal() +
    scale_color_manual(values = colorBlindBlack8)

```

In the past research, the relationship between the vertical position and F0 was frequently pointed to as a robust one, especially in perception, but also in production. Let's see how it looks like in our data:

```{r, warning=FALSE, message=FALSE}
f0_vertical <- ggplot(can,
                      aes(y = f0_mean_z,
                          x = v_pos,
                          color = can_size)) +
  stat_summary(geom = 'line', 
               fun = mean, 
               position = position_dodge(width = 0.5), 
               size = 2) +
  stat_summary(position = position_dodge(width = 0.5), 
               size = 1 ) + 
  scale_color_manual(values=colorBlindBlack8) +
  labs(x = "Vertical Position",
       y = "F0 (z-normalized)",
       color = "Can size") + 
  theme_bw()+
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 16, 
                                  face="bold"),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12))

f0_vertical

# ggsave(plot = f0_vertical, filename = "F0-vertical.pdf", width = 7, height = 4)
```


#### Posterior distribution

```{r}
# Extracting posterior samples 
post_maxH1_vPos <- mdl_maxH1_vPos %>% 
  gather_draws(b_vowel_s, b_can_size_s, b_v_pos, b_h_pos, b_height) 

# Plotting intervals with densities
postplot_maxH1_vPos <- 
  ggplot(post_maxH1_vPos, 
         aes(x = .value, y = .variable)) +
  stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
  geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
               linetype = "dashed", color = "grey", size = 1) + 
  theme_bw() +
  labs(x = "Posterior density", y = "Variable") +
  scale_y_discrete(labels = c("Can size", "Height", "Horizontal pos.", "Vertical pos.", "Vowel")) + # Must be in alphabetical order
  scale_x_continuous(limits = c(-0.13, 0.01))

postplot_maxH1_vPos
```


# Jaw opening

## Calculate area

The idea is to calculate the area of vowel space per speaker per size and compare the areas for large vs. small cans with a simple t-test to have an initial test of the hypothesis.

Solution found here: https://stackoverflow.com/questions/38782051/how-to-calculate-the-area-of-ellipse-drawn-by-ggplot2

Filter vowels and sizes to make plots and ellipsis calculations correct.

```{r}
formants_a_large <- can %>% 
  filter(vowel == "a") %>% 
  filter(.,can_size == 'large')
formants_a_small <- can %>% 
  filter(vowel == "a") %>% 
  filter(.,can_size == 'small')
formants_i_large <- can %>% 
  filter(vowel == "I") %>% 
  filter(.,can_size == 'large')
formants_i_small <- can %>% 
  filter(vowel == "I") %>% 
  filter(.,can_size == 'small')
```

### Vowel a and size large

Plot object

```{r}
area_a_large = ggplot(formants_a_large,
            aes(y = F1,
                x = F2)) +
  geom_point() +
  stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
```

Get ellipse coordinates from plot

```{r}
pb = ggplot_build(area_a_large)
el = pb$data[[2]][c("x", "y")]
```

Center of ellipse

```{r}
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
```

Calculate distance to center from each point on the ellipse

```{r}
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
```

Calculate area of ellipse from semi-major and semi-minor axes. 
These are, respectively, the largest and smallest values of dist2center. 

```{r}
area_a_large <- pi*min(dist2center)*max(dist2center)
area_a_large
```

### Vowel a and size small

Plot object

```{r}
area_a_small = ggplot(formants_a_small,
            aes(y = F1,
                x = F2)) +
  geom_point() +
  stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
```

Get ellipse coordinates from plot

```{r}
pb = ggplot_build(area_a_small)
el = pb$data[[2]][c("x", "y")]
```

Center of ellipse

```{r}
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
```

Calculate distance to center from each point on the ellipse

```{r}
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
```

Calculate area of ellipse from semi-major and semi-minor axes. 
These are, respectively, the largest and smallest values of dist2center. 

```{r}
area_a_small <- pi*min(dist2center)*max(dist2center)
area_a_small
```

### Vowel i and size large

Plot object

```{r}
area_i_large = ggplot(formants_i_large,
            aes(y = F1,
                x = F2)) +
  geom_point() +
  stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
```

Get ellipse coordinates from plot

```{r}
pb = ggplot_build(area_i_large)
el = pb$data[[2]][c("x", "y")]
```

Center of ellipse

```{r}
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
```

Calculate distance to center from each point on the ellipse

```{r}
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
```

Calculate area of ellipse from semi-major and semi-minor axes. 
These are, respectively, the largest and smallest values of dist2center. 

```{r}
area_i_large <- pi*min(dist2center)*max(dist2center)
area_i_large
```

### Vowel i and size small

Plot object

```{r}
area_i_small = ggplot(formants_i_small,
            aes(y = F1,
                x = F2)) +
  geom_point() +
  stat_ellipse(segments = 201) # Default is 51. We use a finer grid for more accurate area.
```

Get ellipse coordinates from plot

```{r}
pb = ggplot_build(area_i_small)
el = pb$data[[2]][c("x", "y")]
```

Center of ellipse

```{r}
ctr = MASS::cov.trob(el)$center  # Per @Roland's comment
```

Calculate distance to center from each point on the ellipse

```{r}
dist2center <- sqrt(rowSums((t(t(el) - ctr))^2))
```

Calculate area of ellipse from semi-major and semi-minor axes. 
These are, respectively, the largest and smallest values of dist2center. 

```{r}
area_i_small <- pi*min(dist2center)*max(dist2center)
area_i_small
```

#### T-test

Create tibble from areas

```{r}
areas <- tribble(
  ~size_large, ~size_small,
  area_a_large, area_a_small,
  area_i_large, area_i_small)
```

And run a t.test on areas

```{r}
t.test(areas$size_large, areas$size_small, paired = T)

```

t-test shows no difference between the vowel space of small and large cans.

Remove unused variables

```{r}
rm(area_a_large,area_a_small,area_i_large,area_i_small,ctr,dist2center,pb,el)
```


## Calculate dispersion

As per reviewer comment, I will calculate formant dispersion and use it for a separate model.

```{r}
can <- can %>%
  mutate(f_disp = ((F2 - F1) + (F3 - F2)) / 2)
```

Let's have a look.

```{r}
can %>%
  group_by(speaker, vowel) %>%
  summarize(mean_f_disp = mean(f_disp, na.rm = TRUE)) %>%
  ungroup() %>%
  print(n = Inf)
```

## Jaw opening vs. F1

There are two possible dependent variables to be tested: F1 and jaw opening.
Let's see what is their correlation in our data:

```{r}
cor.test(can$lip_dist, can$F1)
```

Plotting the raw values...

```{r}
ggplot(can,
       aes(x = lip_dist,
           y = F1)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = F)
```

Very highly correlated, as expected. Let's see about the formant dispersion, as suggested by one of the reviewers.

## Jaw opening vs. formant dispersion


```{r}
cor.test(can$lip_dist, can$f_disp)
```

Plotting the raw values...

```{r}
ggplot(can,
       aes(x = lip_dist,
           y = f_disp)) +
  geom_point(alpha = 0.2) +
  geom_smooth(size = 1, 
              method = lm, 
              se = F)
```

This is very interesting. There are some "whiskers" that are clearly not linear.

Given this interesting observation, I think it is fair to test both outcome variables: jaw opening and formant dispersion.


## Bayesian modeling

Here, I'm computing a model that estimates the probability of an effect of can size (among others) on lip distance and on formant dispersion. The first iteration of this analysis was done with the help of Timo Roettger. Since then, however, the analysis has been upgraded with the comments of three anonymous reviewers and Bodo Winter.

------------------------------------------------------------------------

The variables are already contrast-coded.

We don't know about the distribution of the lip distance and formant dispersion. This is important for choosing the appropriate family.

```{r}
# Histogram for lip_dist
ggplot(can, aes(x = lip_dist)) +
  geom_histogram(bins = 30, fill = "blue", color = "black") +
  labs(title = "Distribution of lip_dist", x = "lip_dist", y = "Frequency") +
  theme_minimal()
# looks kind of normal

# Histogram for f_disp
ggplot(can, aes(x = f_disp)) +
  geom_histogram(bins = 30, fill = "blue", color = "black") +
  labs(title = "Distribution of f_disp", x = "f_disp", y = "Frequency") +
  theme_minimal()
# this is skewed, I would opt for lognormal

# Descriptive Statistics
summary(can$lip_dist)
summary(can$f_disp)

```

While lip distance looks normally distributed, formant dispersion is definitely skewed. I am also a little suspicious of the "normality" in lip_disp. We will fit the priors accordingly to this.

We will also turn to the maximal model in both cases instantly and only if the model will not perform well, we will seek an alternative.

For each model, I will fit weakly informative priors.

I divide in two streams: lip distance and formant dispersion.

### Lip distance

#### Priors

Since this one will be lognormal, let's look what values we can expect.

```{r}
# In intercept is 1000
log(4)

# If we set the prior to normal(0,1), what would be the boundaries
exp(log(4)-.5); exp(log(4)+.5)

# If we set the prior to normal(0,2), what would be the boundaries
exp(log(4)-1); exp(log(4)+1)

# If we set the prior to normal(0,3), what would be the boundaries
exp(log(4)-1.5); exp(log(4)+1.5)
```


```{r}
get_prior(formula = lip_dist ~ 1 + vowel_s + can_size_s + head_pos + h_pos + v_pos + height + # head_pos and v_pos will be separated
            (1 + vowel_s + can_size_s + head_pos + h_pos + v_pos || speaker),
          data = can,
          family = lognormal())
```

I will not specify any priors for the group-level effects.

```{r}
priors_maxH2_lip <- c(
  prior('normal(0, 3)', class = 'Intercept'),
  prior('normal(0, 1)', class = b)
)
```

We have to fit both dependent variables with the two predictors head position and vertical position separately.

#### Fit models

##### Head position

```{r}
mdl_maxH2_lip_headPos <- brm(lip_dist ~ 
                               1 + vowel_s + can_size_s + 
                               head_pos + h_pos + height +
                      (1 + vowel_s + can_size_s + 
                         head_pos + h_pos || speaker),
                   data = can,
                   prior = priors_maxH2_lip,
                   family = lognormal(),
                   #backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_maxH2_lip_headPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_maxH2_lip_headPos, file = paste0(models, "mdl_maxH2_lip_headPos.rds"), compress = "xz")

mdl_maxH2_lip_headPos <- readRDS(paste0(models, "mdl_maxH2_lip_headPos.rds"))

beepr::beep()
```

Let's check how it looks like.

```{r}
summary(mdl_maxH2_lip_headPos)
```

```{r}
plot(mdl_maxH2_lip_headPos)
```

```{r}
conditional_effects(mdl_maxH2_lip_headPos, sample_prior = "only")
```

```{r}
pp_check(mdl_maxH2_lip_headPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_maxH2_lip_headPos_loo.rds"))) {
  mdl_maxH2_lip_headPos_loo <- readRDS(paste0(models, "mdl_maxH2_lip_headPos_loo.rds"))
} else {
  mdl_maxH2_lip_headPos_loo <- loo(mdl_maxH2_lip_headPos, moment_match = TRUE)
  saveRDS(mdl_maxH2_lip_headPos_loo, paste0(models, "mdl_maxH2_lip_headPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_maxH2_lip_headPos_loo
```

See if any [reloo](https://paul-buerkner.github.io/brms/reference/reloo.html) is needed.

```{r}
if (file.exists(paste0(models, "mdl_maxH2_lip_headPos_reloo.rds"))) {
  mdl_maxH2_lip_headPos_reloo <- readRDS(paste0(models, "mdl_maxH2_lip_headPos_reloo.rds"))
} else {
  mdl_maxH2_lip_headPos_reloo <- reloo(mdl_maxH2_lip_headPos_loo, mdl_maxH2_lip_headPos, chains = 1)
  saveRDS(mdl_maxH2_lip_headPos_reloo, paste0(models, "mdl_maxH2_lip_headPos_reloo.rds"))
}

mdl_maxH2_lip_headPos_reloo
```


##### Vertical position


```{r}
mdl_maxH2_lip_vPos <- brm(lip_dist ~ 1 + vowel_s + can_size_s + 
                      h_pos + v_pos + height +
                      (1 + vowel_s + can_size_s + 
                         h_pos + v_pos || speaker),
                   data = can,
                   prior = priors_maxH2_lip,
                   family = lognormal(),
                   #backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_maxH2_lip_vPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_maxH2_lip_vPos, file = paste0(models, "mdl_maxH2_lip_vPos.rds"), compress = "xz")

mdl_maxH2_lip_vPos <- readRDS(paste0(models, "mdl_maxH2_lip_vPos.rds"))

beepr::beep()
```

Let's check how it looks like.

```{r}
summary(mdl_maxH2_lip_vPos)
```

```{r}
plot(mdl_maxH2_lip_vPos)
```

```{r}
conditional_effects(mdl_maxH2_lip_vPos, sample_prior = "only")
```

```{r}
pp_check(mdl_maxH2_lip_vPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_maxH2_lip_vPos_loo.rds"))) {
  mdl_maxH2_lip_vPos_loo <- readRDS(paste0(models, "mdl_maxH2_lip_vPos_loo.rds"))
} else {
  mdl_maxH2_lip_vPos_loo <- loo(mdl_maxH2_lip_vPos, moment_match = TRUE)
  saveRDS(mdl_maxH2_lip_vPos_loo, paste0(models, "mdl_maxH2_lip_vPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_maxH2_lip_vPos_loo
```

#### Analysis of the models

##### Head position

We would expect:

- vowel_s to have a positive effect on lip_dist, because -0.5 is [i], and 0.5 is [a], and [a] should have a larger lip distance being an open vowel
- head_pos -- no expectation
- height -- no expectation
- can_size_s to have a negative effect on lip_dist, because -0.5 is small, and 0.5 is large, and our hypothesis says that iconically smaller object would yield smaller aperture
- h_pos -- no expectation

First, let's look at the summary again.

```{r}
summary(mdl_maxH2_lip_headPos)
```

All hypotheses tested together:

```{r}
hypothesis(mdl_maxH2_lip_headPos, c("vowel_s > 0", "head_pos > 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH1_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
```

A summary of the findings from the data, the priors, and the model:

- vowel_s has a positive effect on lip_dist, such that from -0.5 [i], to 0.5 [a] the lip distance increases
- head_pos has a positive effect on lip_dist, such that when head position increases, the lip distance increases
- height has a negative effect on lip_dist such that taller participants generally have smaller lip distance
- can_size_s has no meaningful effect -- our hypothesis is refuted
- h_pos has no meaningful effect

Change to report:

```{r}
summary(can$lip_dist) # the unit is centimeters

exp(fixef(mdl_maxH2_lip_headPos))

exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # intercept in cm
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[4,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate head_pos in cm (positive), i.e., every 1 cm change in head_pos causes a change in lip_dist of
(exp(fixef(mdl_maxH2_lip_headPos)[1,1])*exp(fixef(mdl_maxH2_lip_headPos)[2,1]))-exp(fixef(mdl_maxH2_lip_headPos)[1,1]) # estimate vowel_s in cm, i.e., difference between a and i is 50 mm
```

##### Vertical position

We would expect:

- vowel_s to have a positive effect on lip_dist, because -0.5 is [i], and 0.5 is [a], and [a] should have a larger lip distance being an open vowel
- v_pos -- no expectation
- height -- no expectation
- can_size_s to have a negative effect on lip_dist, because -0.5 is small, and 0.5 is large, and our hypothesis says that iconically smaller object would yield smaller aperture
- h_pos -- no expectation

First, let's look at the summary again.

```{r}
summary(mdl_maxH2_lip_vPos)
```

All hypotheses tested together:

```{r}
hypothesis(mdl_maxH2_lip_vPos, c("vowel_s > 0", "v_pos < 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH2_lip_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
```

A summary of the findings from the data, the priors, and the model:

- vowel_s has a positive effect on lip_dist, such that from -0.5 [i], to 0.5 [a] the lip distance increases
- v_pos has a negative effect on lip_dist, such that when the vertical position decreases, the lip distance decreases, too
- height has no meaningful effect in this model!
- can_size_s has no meaningful effect -- our hypothesis is refuted
- h_pos has no meaningful effect

Change to report:

```{r}
summary(can$lip_dist) # the unit is centimeters

exp(fixef(mdl_maxH2_lip_vPos))

exp(fixef(mdl_maxH2_lip_vPos)[1,1]) # intercept in cm
(exp(fixef(mdl_maxH2_lip_vPos)[1,1])*exp(fixef(mdl_maxH2_lip_vPos)[4,1]))-exp(fixef(mdl_maxH2_lip_vPos)[1,1]) # estimate v_pos in cm (positive), i.e., every step change in v_pos causes a change in lip_dist of 3 mm
(exp(fixef(mdl_maxH2_lip_vPos)[1,1])*exp(fixef(mdl_maxH2_lip_vPos)[2,1]))-exp(fixef(mdl_maxH2_lip_vPos)[1,1]) # estimate vowel_s in cm, i.e., difference between a and i is 50 mm
```


#### Plots


##### Jaw opening (old)

Let's see what's the relationship between size and jaw opening:

```{r, warning=FALSE, message=FALSE}
lip <- ggplot(can,
              aes(y = lip_dist,
                  x = vowel,
                  fill = can_size)) +
  geom_violin(position = position_dodge(1),
              trim = FALSE,
              alpha = 0.4) +
  # adds median and quartile:
  geom_boxplot(width = 0.1,
               position = position_dodge((1)),
               alpha = 0.6,
               outlier.shape = NA, # Hides outliers.
               notch = T, #  Notches are used to compare groups; if the notches of two boxes do not overlap, this suggests that the medians are significantly different.
               coef = 0) + # Length of the whiskers as multiple of IQR. Defaults to 1.5. 
  scale_fill_manual(values = colorBlindBlack8) +
  labs(x = "Vowel",
       y = "Lip opening",
       fill = "Can size") + 
  theme_bw()+
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 16),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12))

lip

# ggsave(plot = lip, filename = "lip.pdf", width = 6, height = 4)
```

The lower and upper hinges correspond to the first and third quartiles (the 25th and 75th percentiles). There are no whiskers to make the plot more clear.

The vowel does make a big difference, but the size has no effect.

##### Posterior distribution

```{r}
# Extracting posterior samples 
post_maxH2_lip_headPos <- mdl_maxH2_lip_headPos %>% 
  gather_draws(b_vowel_s, b_can_size_s, b_head_pos, b_h_pos, b_height) 

# Plotting intervals with densities
postplot_maxH2_lip_headPos <- 
  ggplot(post_maxH2_lip_headPos, 
         aes(x = .value, y = .variable)) +
  stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
  geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
               linetype = "dashed", color = "grey", size = 1) + 
  theme_bw() +
  labs(x = "Posterior density", y = "Variable") +
  scale_y_discrete(labels = c("Can size", "Head position", "Height", "Horizontal pos.", "Vowel")) #+ # Must be in alphabetical order
  #scale_x_continuous(limits = c(-0.13, 0.01))

postplot_maxH2_lip_headPos
```


```{r}
# Extracting posterior samples 
post_maxH2_lip_vPos <- mdl_maxH2_lip_vPos %>% 
  gather_draws(b_vowel_s, b_can_size_s, b_v_pos, b_h_pos, b_height) 

# Plotting intervals with densities
postplot_maxH2_lip_vPos <- 
  ggplot(post_maxH2_lip_vPos, 
         aes(x = .value, y = .variable)) +
  stat_halfeye(.width = 0.95, fill = colorBlindBlack8[2], alpha = 0.7, size = 2) +
  geom_segment(x = 0, xend = 0, y = -Inf, yend = Inf,
               linetype = "dashed", color = "grey", size = 1) + 
  theme_bw() +
  labs(x = "Posterior density", y = "Variable") +
  scale_y_discrete(labels = c("Can size", "Height", "Horizontal pos.", "Vertical pos.", "Vowel")) #+ # Must be in alphabetical order
  #scale_x_continuous(limits = c(-0.13, 0.01))

postplot_maxH2_lip_vPos
```


### Formant dispersion

#### Priors

Since this one will be lognormal, let's look what values we can expect.

```{r}
# In intercept is 1000
log(1000)

# If we set the prior to normal(0,5), what would be the boundaries
exp(log(1000)-2.5); exp(log(1000)+2.5)

# If we set the prior to normal(0,4), what would be the boundaries
exp(log(1000)-2); exp(log(1000)+2)

# If we set the prior to normal(0,3), what would be the boundaries
exp(log(1000)-1.5); exp(log(1000)+1.5)
```


```{r}
get_prior(formula = f_disp ~ 1 + vowel_s + can_size_s + head_pos + h_pos + v_pos + height + # head_pos and v_pos will be separated
            (1 + vowel_s + can_size_s + head_pos + h_pos + v_pos || speaker),
          data = can,
          family = lognormal())
```

I will not specify any priors for the group-level effects.

```{r}
priors_maxH2_form <- c(
  prior('normal(0, 4)', class = 'Intercept'),
  prior('normal(0, 1)', class = b)
)
```

We have to fit both dependent variables with the two predictors head position and vertical position separately.

#### Fit models

##### Head position

```{r}
mdl_maxH2_form_headPos <- brm(f_disp ~ 
                               1 + vowel_s + can_size_s + 
                               head_pos + h_pos + height +
                      (1 + vowel_s + can_size_s + 
                         head_pos + h_pos || speaker),
                   data = can,
                   prior = priors_maxH2_form,
                   family = lognormal(),
                   #backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_maxH2_form_headPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_maxH2_form_headPos, file = paste0(models, "mdl_maxH2_form_headPos.rds"), compress = "xz")

mdl_maxH2_form_headPos <- readRDS(paste0(models, "mdl_maxH2_form_headPos.rds"))

beepr::beep()
```

Let's check how it looks like.

```{r}
summary(mdl_maxH2_form_headPos)
```

```{r}
plot(mdl_maxH2_form_headPos)
```

```{r}
conditional_effects(mdl_maxH2_form_headPos, sample_prior = "only")
```

```{r}
pp_check(mdl_maxH2_form_headPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_maxH2_form_headPos_loo.rds"))) {
  mdl_maxH2_form_headPos_loo <- readRDS(paste0(models, "mdl_maxH2_form_headPos_loo.rds"))
} else {
  mdl_maxH2_form_headPos_loo <- loo(mdl_maxH2_form_headPos, moment_match = TRUE)
  saveRDS(mdl_maxH2_form_headPos_loo, paste0(models, "mdl_maxH2_form_headPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_maxH2_form_headPos_loo
```

See if any [reloo](https://paul-buerkner.github.io/brms/reference/reloo.html) is needed.

```{r}
if (file.exists(paste0(models, "mdl_maxH2_form_headPos_reloo.rds"))) {
  mdl_maxH2_form_headPos_reloo <- readRDS(paste0(models, "mdl_maxH2_form_headPos_reloo.rds"))
} else {
  mdl_maxH2_form_headPos_reloo <- reloo(mdl_maxH2_form_headPos_loo, mdl_maxH2_form_headPos, chains = 1)
  saveRDS(mdl_maxH2_form_headPos_reloo, paste0(models, "mdl_maxH2_form_headPos_reloo.rds"))
}

mdl_maxH2_form_headPos_reloo
```


##### Vertical position


```{r}
mdl_maxH2_form_vPos <- brm(f_disp ~ 1 + vowel_s + can_size_s + 
                      h_pos + v_pos + height +
                      (1 + vowel_s + can_size_s + 
                         h_pos + v_pos || speaker),
                   data = can,
                   prior = priors_maxH2_form,
                   family = lognormal(),
                   #backend = "cmdstanr",
                   cores = 4,
                   chains = 4,
                   iter = 8000,
                   warmup = 4000,
                   seed = 998,
                   save_pars = save_pars(all = TRUE),
                   control = list(max_treedepth = 13,
                                  adapt_delta = 0.99),
                   file = paste0(models, "mdl_maxH2_form_vPos.rds"))

# if we need to compress the model more
#saveRDS(mdl_maxH2_form_vPos, file = paste0(models, "mdl_maxH2_form_vPos.rds"), compress = "xz")

mdl_maxH2_form_vPos <- readRDS(paste0(models, "mdl_maxH2_form_vPos.rds"))

beepr::beep()
```

Let's check how it looks like.

```{r}
summary(mdl_maxH2_form_vPos)
```

```{r}
plot(mdl_maxH2_form_vPos)
```

```{r}
conditional_effects(mdl_maxH2_form_vPos, sample_prior = "only")
```

```{r}
pp_check(mdl_maxH2_form_vPos, ndraws = 100)
```

Let's compute the loo for model comparison.

```{r}
# run loo mdl
if (file.exists(paste0(models, "mdl_maxH2_form_vPos_loo.rds"))) {
  mdl_maxH2_form_vPos_loo <- readRDS(paste0(models, "mdl_maxH2_form_vPos_loo.rds"))
} else {
  mdl_maxH2_form_vPos_loo <- loo(mdl_maxH2_form_vPos, moment_match = TRUE)
  saveRDS(mdl_maxH2_form_vPos_loo, paste0(models, "mdl_maxH2_form_vPos_loo.rds"))
}
```

Check the loo.

```{r}
mdl_maxH2_form_vPos_loo
```

See if any [reloo](https://paul-buerkner.github.io/brms/reference/reloo.html) is needed.

```{r}
if (file.exists(paste0(models, "mdl_maxH2_form_vPos_reloo.rds"))) {
  mdl_maxH2_form_vPos_reloo <- readRDS(paste0(models, "mdl_maxH2_form_vPos_reloo.rds"))
} else {
  mdl_maxH2_form_vPos_reloo <- reloo(mdl_maxH2_form_vPos_loo, mdl_maxH2_form_vPos, chains = 1)
  saveRDS(mdl_maxH2_form_vPos_reloo, paste0(models, "mdl_maxH2_form_vPos_reloo.rds"))
}

mdl_maxH2_form_vPos_reloo
```

#### Analysis of the models


##### Head position

We would expect:

- vowel_s -- no expectation
- head_pos -- no expectation
- height -- no expectation
- can_size_s to have a negative effect on f_disp, because -0.5 is small, and 0.5 is large, and our hypothesis says that iconically smaller object would yield smaller aperture
- h_pos -- no expectation

First, let's look at the summary again.

```{r}
summary(mdl_maxH2_form_headPos)
```

All hypotheses tested together:

```{r}
hypothesis(mdl_maxH2_form_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH2_form_headPos, c("vowel_s < 0", "head_pos > 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
```

A summary of the findings from the data, the priors, and the model:

- vowel_s has a negative effect on f_disp, such that from -0.5 [i], to 0.5 [a] the lip distance desreases
- head_pos has no meaningful effect
- height has no meaningful effect
- can_size_s has no meaningful effect -- our hypothesis is refuted
- h_pos has no meaningful effect

Change to report:

```{r}
summary(can$f_disp) # the unit is Hz

exp(fixef(mdl_maxH2_form_headPos))

exp(fixef(mdl_maxH2_form_headPos)[1,1]) # intercept in Hz
(exp(fixef(mdl_maxH2_form_headPos)[1,1])*exp(fixef(mdl_maxH2_form_headPos)[4,1]))-exp(fixef(mdl_maxH2_form_headPos)[1,1]) # estimate head_pos in Hz (positive), i.e., every 1 cm change in head_pos causes a change in formant dispersion of... (not reliable though)
(exp(fixef(mdl_maxH2_form_headPos)[1,1])*exp(fixef(mdl_maxH2_form_headPos)[2,1]))-exp(fixef(mdl_maxH2_form_headPos)[1,1])  # estimate vowel_s in Hz (negative), i.e., the formant dispersion difference between a and i
```

##### Vertical position

We would expect:

- vowel_s to have a positive effect on lip_dist, because -0.5 is [i], and 0.5 is [a], and [a] should have a larger lip distance being an open vowel
- v_pos -- no expectation
- height -- no expectation
- can_size_s to have a negative effect on lip_dist, because -0.5 is small, and 0.5 is large, and our hypothesis says that iconically smaller object would yield smaller aperture
- h_pos -- no expectation

First, let's look at the summary again.

```{r}
summary(mdl_maxH2_form_vPos)
```

All hypotheses tested together:

```{r}
hypothesis(mdl_maxH2_form_vPos, c("vowel_s < 0", "v_pos > 0", "height < 0", "can_size_s > 0", "h_pos > 0"))
plot(hypothesis(mdl_maxH2_lip_vPos, c("vowel_s < 0", "v_pos < 0", "height < 0", "can_size_s < 0", "h_pos > 0")))
```

A summary of the findings from the data, the priors, and the model:

- vowel_s has a positive effect on lip_dist, such that from -0.5 [i], to 0.5 [a] the lip distance increases
- v_pos has a negative effect on lip_dist, such that when the vertical position decreases, the lip distance decreases, too
- height has no meaningful effect in this model!
- can_size_s has no meaningful effect -- our hypothesis is refuted
- h_pos has no meaningful effect

Change to report:

```{r}
summary(can$f_disp) # the unit is centimeters

exp(fixef(mdl_maxH2_form_vPos))

exp(fixef(mdl_maxH2_form_vPos)[1,1]) # intercept in cm
(exp(fixef(mdl_maxH2_form_vPos)[1,1])*exp(fixef(mdl_maxH2_form_vPos)[4,1]))-exp(fixef(mdl_maxH2_form_vPos)[1,1]) # estimate head_pos in Hz (positive), i.e., every 1 cm change in head_pos causes a change in formant dispersion of... (not reliable though)
(exp(fixef(mdl_maxH2_form_vPos)[1,1])*exp(fixef(mdl_maxH2_form_vPos)[2,1]))-exp(fixef(mdl_maxH2_form_vPos)[1,1])  # estimate vowel_s in Hz (negative), i.e., the formant dispersion difference between a and i
```


#### Plots

##### Formants (old but modified)

Scatter plot of F1 and F2:

```{r, warning=FALSE, message=FALSE}
scatter_formant_v <- ggplot(can,
                              aes(y = F2,
                                  x = F1,
                                  color = vowel)) +
  geom_point(alpha = 0.2) +
  stat_ellipse(segments = 51, 
               size = 1)  +
  scale_color_manual(values = colorBlindBlack8) +
  labs(x = "F1",
       y = "F2",
       color = "Vowel")

print(scatter_formant_v +
        facet_wrap(~can_size) +
        theme_bw() +
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 16),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12)))
```

The difference between the vowels is clearly visible, according to articulatory phonetics.

What happens if we switch plot the vowels on separate plots and sizes on the same? The t-test suggests there will be no difference, but let's have a look.

```{r, warning=FALSE, message=FALSE}
scatter_formant_size <- ggplot(can,
                              aes(y = F2,
                                  x = F1,
                                  color = can_size)) +
        facet_wrap(~vowel) +
  geom_point(alpha = 0.2) +
  stat_ellipse(segments = 51, 
               size = 1)  +
  scale_color_manual(values = colorBlindBlack8) +
  labs(y = "F2",
       x = "F1",
       color = "Can size") +
  theme_bw() +
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 16),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12))

scatter_formant_size

# ggsave(plot = scatter_z_formant, filename = "size_vowel.pdf", width = 7, height = 4)
```

Exactly as already predicted by the t-test, there is no difference of vowels space between large and small cans.

I will show it again using the phonR package:

```{r}
vowel_space <- with(can, plotVowels(F1, F2, vowel,
                                  group = can_size,
                                  plot.tokens = FALSE,
                                  plot.means = TRUE,
                                  pch.means = vowel,
                                  cex.means = 2,
                                  var.col.by = can_size,
                                  var.sty.by = can_size,
                                  ellipse.fill = T,
                                  poly.line = T,
                                  pretty = T,
                                  col = colorBlindBlack8,
                                  legend.kwd = "bottomleft",
                                  cex.lab = 1.2,
                                  cex.axis = 1
                                  #main = "Z"
                                  ))

#ggsave(plot = vowel_space_Z, filename = "size-vowel-phonR.pdf", width = 7, height = 4)

```

Just for comparison, let's have a look at bark scale instead of Z normalized values:

```{r}
vowel_space_bark <- with(can, plotVowels(F1_bark, F2_bark, vowel,
                                  group = can_size,
                                  plot.tokens = FALSE,
                                  plot.means = TRUE,
                                  pch.means = vowel,
                                  cex.means = 1.5,
                                  var.col.by = can_size,
                                  var.sty.by = can_size,
                                  #ylim = c(10,3),
                                  #xlim = c(15,8),
                                  ellipse.fill = T,
                                  poly.line = T,
                                  pretty = T,
                                  legend.kwd = "bottomleft",
                                  main = "Bark"))
```

Just for the sake of it, we can also look how it looks in vertical position 1, where the effect looked most robust:

```{r}
# First, filter the data:
formant_v1 <- filter(can, v_pos == '1')

# And then plot it:
size_vowel_v1 <- ggplot(formant_v1,
       aes(y = F1,
           x = F2,
           color = can_size)) +
  geom_point(alpha = 0.2) +
  stat_ellipse(segments = 51,
               size = 1) + 
  scale_color_manual(values=colorBlindBlack8) +
  labs(x = "F1",
       y = "F2",
       color = "Can size") +
  facet_wrap(~vowel) +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 16),
        legend.title = element_text(size = 14),
        legend.text = element_text(size = 12))

size_vowel_v1

# ggsave(plot = size_vowel_v1, filename = "size_vowel_v1.pdf", width = 7, height = 4)

```

The difference is more visible, but still it is barely there.

##### New plots

```{r, warning=FALSE, message=FALSE}
p_fDisp_vowel_size <- ggplot(can,
              aes(y = f_disp,
                  x = vowel,
                  fill = can_size)) +
  geom_violin(position = position_dodge(1),
              trim = FALSE,
              alpha = 0.4) +
  # adds median and quartile:
  geom_boxplot(width = 0.1,
               position = position_dodge((1)),
               alpha = 0.6,
               outlier.shape = NA, # Hides outliers.
               notch = T, #  Notches are used to compare groups; if the notches of two boxes do not overlap, this suggests that the medians are significantly different.
               coef = 0) + # Length of the whiskers as multiple of IQR. Defaults to 1.5. 
  scale_fill_manual(values = colorBlindBlack8) +
  labs(x = "Vowel",
       y = "Formant dispersion",
       fill = "Can size") + 
  theme_bw()+
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 16),
              legend.title = element_text(size = 14),
              legend.text = element_text(size = 12))

p_fDisp_vowel_size

# ggsave(plot = lip, filename = "lip.pdf", width = 6, height = 4)
```

The vowel makes a big difference, but the formant dispersion doesn't seem to make any.
